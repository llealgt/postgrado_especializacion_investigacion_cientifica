{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"../datos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos  = pd.read_excel(DATA_DIRECTORY+\"RESUMEN TAC CEREBRALES.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario cuya llave es el id de paciente y el valor una lista \n",
    "# donde cada elemento de la lista es la matriz de una i\n",
    "diccionario_imagenes_pacientes = dict()\n",
    "\n",
    "for paciente in diagnosticos.paciente:\n",
    "    directorio_paciente = DATA_DIRECTORY+\"paciente_\"+str(paciente)\n",
    "    archivos_paciente = os.listdir(directorio_paciente)\n",
    "    \n",
    "    lista_imagenes_paciente = []\n",
    "    for archivo in archivos_paciente:\n",
    "        if archivo.endswith(\".jpg\"):\n",
    "            imagen = mpimg.imread(directorio_paciente+\"/\"+archivo)\n",
    "            lista_imagenes_paciente.append(imagen)\n",
    "            \n",
    "    diccionario_imagenes_pacientes[paciente] = lista_imagenes_paciente\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos y arquitecturas\n",
    "### Arquitecturas experimental  DNC\n",
    "* Alimentamos al modelo imagen por imagen y se presenta un solo diagnostico por paciente\n",
    "* El controller de la DNC esta compuesto por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_OUTPUT_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "class ConvController(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,4,kernel_size=3,stride=1)\n",
    "        self.fc1  =  torch.nn.Linear(262144,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h = self.conv1(x)\n",
    "        \n",
    "        #flatten\n",
    "        h =  x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        h =  self.fc1(h)\n",
    "        \n",
    "        return h #h_t in my txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "#TODO: cordar por que en algun momento le puse bias = False a los pesos del vector de salida de la DNC\n",
    "class DNC(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,controller,memory_size = (10,10),read_heads = 1):\n",
    "        super().__init__()\n",
    "        self.controller = controller\n",
    "        self.N = memory_size[0] # number of memory locations\n",
    "        self.W = memory_size[1] # word size of the memory \n",
    "        self.R = read_heads # number of read heads\n",
    "        self.WS = 1 #not in the paper(they use 1), but used as a parametrizable number of write heads for further experiments\n",
    "        self.interface_vector_size = (self.W*self.R) + (self.W*self.WS) + (2*self.W) + (5*self.R) + 3\n",
    "        \n",
    "        # inicialization st to random just for testing, remember to put on zeros\n",
    "        self.memory_matrix = self.memory_matrix =  nn.Parameter(torch.randn(size=memory_size),requires_grad= False) \n",
    "        \n",
    "        #1024 es el tamaño del vector de salida del controlador, 1 es el tamaño de salida de la dnc\n",
    "        self.output_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,1,bias=False) #W_y \n",
    "        self.interface_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,self.interface_vector_size,bias=False) #W_ξ\n",
    "        self.read_vectors_to_output_linear = torch.nn.Linear(self.R*self.W,1,bias = False) #W_r in my txt\n",
    "        \n",
    "        self.read_keys = torch.Tensor(size=(self.R,self.W)).requires_grad_(False) # k_r in my txt\n",
    "        self.read_strenghts = torch.Tensor(size=(self.R,1)).requires_grad_(False) #β_r\n",
    "        \n",
    "        self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(False) #r_w\n",
    "        \n",
    "        self.write_key = torch.Tensor(size=(1,self.W)).requires_grad_(False) # k_w in my txt\n",
    "        self.write_strenght = torch.Tensor(size=(1,1)).requires_grad_(False) # β_w\n",
    "        \n",
    "        self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) # w_w\n",
    "        \n",
    "        self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) #u_t\n",
    "        \n",
    "        self.memory_matrix_ones = torch.Tensor(torch.ones(size=memory_size)).requires_grad_(False) #E on paper\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h_t = self.controller(x) #controller output called ht in the paper\n",
    "        \n",
    "        output_vector = self.output_vector_linear(h_t) # called Vt in the paper(υ=Wy[h1;...;hL]) v_o_t in my txt\n",
    "        interface_vector = self.interface_vector_linear(h_t).data #called ξt(ksi) in the paper ,ξ_t in my txt\n",
    "        \n",
    "        self.read_keys.data = interface_vector[0,0:self.R*self.W].view((self.R,self.W)) #k_r in my txt\n",
    "        \n",
    "        #clamp temporary added because the exp was returning inf  values\n",
    "        read_strenghts =  torch.clamp( interface_vector[0,self.R*self.W:self.R*self.W+self.R].view((self.R,1)),max=85)\n",
    "        self.read_strenghts.data = self.oneplus(read_strenghts) #β_r\n",
    "        \n",
    "        self.write_key.data = interface_vector[0,self.R*self.W+self.R:self.R*self.W+self.R+self.W].view((1,self.W)) # k_w\n",
    "        \n",
    "        write_strenght = torch.clamp(interface_vector[:,self.R*self.W+self.R+self.W:self.R*self.W+self.R+self.W + 1].view((1,1)),max=85)\n",
    "        self.write_strenght.data = self.oneplus(write_strenght) #β_w\n",
    "        \n",
    "        erase_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1: self.R*self.W+self.R+self.W + 1 + self.W].view((1,self.W))\n",
    "        erase_vector = torch.sigmoid(erase_vector) #e_t\n",
    "        \n",
    "        write_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1 + self.W:self.R*self.W+self.R+self.W + 1 + 2*self.W].view((1,self.W)) #v_t\n",
    "        \n",
    "        free_gates  =  interface_vector[0,self.R*self.W+self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W].view((self.R,1)) #f_t\n",
    "        free_gates =   torch.sigmoid(free_gates)\n",
    "        \n",
    "        allocation_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1]\n",
    "        allocation_gate = torch.sigmoid(allocation_gate)\n",
    "        \n",
    "        write_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+2]\n",
    "        write_gate = torch.sigmoid( write_gate)\n",
    "        \n",
    "        \n",
    "        # Escritura\n",
    "        # TODO: verificar y/o experimentar si el ordern es :primero escribir y luego leer de la memoria(asi parece en el pazper)\n",
    "        print(\"free gates\",free_gates,free_gates.size())\n",
    "        print(\"read wei\",self.read_weighting,self.read_weighting.size())\n",
    "        retention_vector = (1.0 - free_gates * self.read_weighting).prod(dim=0)\n",
    "        print(\"pre usage\",self.usage_vector)\n",
    "        print(\"write weit\",self.write_weighting)\n",
    "        print(\"retention\",retention_vector)\n",
    "        self.usage_vector.data = (self.usage_vector +self.write_weighting - (self.usage_vector *self.write_weighting))*retention_vector #u_t\n",
    "        print(\"post usage\",self.usage_vector)\n",
    "        allocation_weighting = self.calc_allocation_weighting(self.usage_vector)\n",
    "        print(\"allo\",allocation_weighting)\n",
    "        print(\"-------------------------------------------------\")\n",
    "        write_content_weighting = self.content_lookup(self.memory_matrix,self.write_key,self.write_strenght)\n",
    "\n",
    "        self.write_weighting.data =  write_gate*(  \n",
    "            (allocation_gate * allocation_weighting) +  ((1- allocation_gate)*write_content_weighting))\n",
    "        print(\"write weighting\",self.write_weighting)\n",
    "        \n",
    "        new_memory_matrix = self.memory_matrix*(self.memory_matrix_ones - torch.matmul(self.write_weighting.t(),erase_vector)) + torch.matmul(self.write_weighting.t(),write_vector)\n",
    "        \n",
    "        self.memory_matrix.data = new_memory_matrix\n",
    "        \n",
    "        # read by content weithing(attention by similarity)\n",
    "        read_content_weighting = self.content_lookup(self.memory_matrix,self.read_keys,self.read_strenghts)\n",
    "        \n",
    "        #read weithing is a combination of reading modes,TODO:add temporal attention not just by similarity\n",
    "        self.read_weighting.data = read_content_weighting\n",
    "        \n",
    "        read_vectors = torch.matmul(self.read_weighting,self.memory_matrix).view((1,self.R*self.W)) #r in my txt\n",
    "        read_heads_to_output = self.read_vectors_to_output_linear(read_vectors) #v_r_t in my t xt\n",
    "        \n",
    "        #TODO: experiment and decide if maintain sigmoid\n",
    "        y_t = torch.sigmoid(output_vector + read_heads_to_output)\n",
    "        return y_t\n",
    "    \n",
    "    def oneplus(self,x):\n",
    "        # apply oneplus operation to a tensor to constrain it's elements to [1,inf)\n",
    "        #TODO: check numerical statiliby as exp is returning inf for numbers like 710,emporary added clamp to 85\n",
    "        return torch.log(1+torch.exp(x)) + 1\n",
    "    \n",
    "    def content_lookup(self,matrix,keys,strengths):\n",
    "        # returns a probability distribution over the memory locations \n",
    "        # with higher probability to memory locations with bigger similarity to the keys\n",
    "        # bigger strenght make more aggresive distributions ,for example a distribution (0.2,0.3,0.5) with\n",
    "        # bigger strenght becomes (0.1,0.12,0.78)\n",
    "        # returns tensor of shape (read keys,memory size) = (R,N)\n",
    "        keys_norm =  torch.sqrt(torch.sum(keys**2,dim=1).unsqueeze(dim=1))\n",
    "        matrix_norm = torch.sqrt(torch.sum(matrix**2,dim=1))\n",
    "        norms_multiplication = keys_norm*matrix_norm\n",
    "        # calc cosine similarity between keys and memory locations(1e-6 is used avoiding div by 0)\n",
    "        divide_zero_prevent_factor = torch.zeros_like(norms_multiplication,requires_grad=False).add_(1e-6)\n",
    "        cosine_similarity = torch.matmul(keys,matrix.t())/(torch.max(norms_multiplication,divide_zero_prevent_factor))\n",
    "        \n",
    "        # do a \"strenght\" softmax to calculate the probability distribution\n",
    "        numerator = torch.exp(cosine_similarity*strengths)\n",
    "        denominator = numerator.sum(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        distribution = numerator/denominator\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def calc_allocation_weighting(self,usage_vector):\n",
    "        #print(\"usage vector\",usage_vector)\n",
    "        _,free_list = torch.topk(-usage_vector,self.N,dim=1) #φt indices of memory locations ordered by usage\n",
    "        #print(\"free list\",free_list)\n",
    "        free_list = free_list.view(-1)\n",
    "        #print(\"reshaped free list\",free_list)\n",
    "        _,ordered_free_list =  torch.topk(-free_list,self.N)\n",
    "        ordered_free_list = ordered_free_list.view(-1)\n",
    "        #print(\"ordered free list\",ordered_free_list)\n",
    "        ordered_usage_vector = usage_vector[:,free_list]\n",
    "        #print(\"ordered usage vector\",ordered_usage_vector)\n",
    "        ordered_usage_vector_cumulative_product = torch.ones(size=(1,self.N+1))\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        #print(\"cumprod \",ordered_usage_vector.cumprod(dim=1))\n",
    "        ordered_usage_vector_cumulative_product[0,1:] = ordered_usage_vector.cumprod(dim=1)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        \n",
    "        allocation_weighting = (1 - usage_vector)*ordered_usage_vector_cumulative_product[0,ordered_free_list]\n",
    "        \n",
    "        return  allocation_weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "* Experimentando con DNC alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_controller = ConvController()\n",
    "dnc_model = DNC(controller=conv_controller,memory_size = (4,4),read_heads=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y,y_hat,last_flag):\n",
    "    #print(y,y_hat,last_flag)\n",
    "    base_criterion = torch.nn.BCELoss()\n",
    "    return torch.full_like(y,last_flag) * base_criterion(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_function\n",
    "optimizer = optim.Adam(dnc_model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alimentando paciente 3 e imagen 14 al modelo (512, 512)\n",
      "free gates tensor([[0.9959],\n",
      "        [0.9999]]) torch.Size([2, 1])\n",
      "read wei tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0., 0., 0., 0.]])\n",
      "write weit tensor([[0., 0., 0., 0.]])\n",
      "retention tensor([1., 1., 1., 1.])\n",
      "post usage tensor([[0., 0., 0., 0.]])\n",
      "allo tensor([[1., 0., 0., 0.]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[1.9670e-08, 3.4055e-23, 1.9786e-24, 1.5100e-14]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda2/envs/pytorch_challenge/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alimentando paciente 3 e imagen 6 al modelo (512, 512)\n",
      "free gates tensor([[9.9967e-01],\n",
      "        [2.8433e-06]]) torch.Size([2, 1])\n",
      "read wei tensor([[3.2218e-01, 2.9685e-02, 6.3084e-10, 6.4814e-01],\n",
      "        [2.8406e-01, 2.6175e-01, 1.6521e-01, 2.8898e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0., 0., 0., 0.]])\n",
      "write weit tensor([[1.9670e-08, 3.4055e-23, 1.9786e-24, 1.5100e-14]])\n",
      "retention tensor([0.6779, 0.9703, 1.0000, 0.3521])\n",
      "post usage tensor([[1.3335e-08, 3.3045e-23, 1.9785e-24, 5.3162e-15]])\n",
      "allo tensor([[0.0000e+00, 1.9785e-24, 1.0000e+00, 0.0000e+00]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[0.0000e+00, 1.9462e-24, 9.8366e-01, 0.0000e+00]])\n",
      "Alimentando paciente 3 e imagen 0 al modelo (512, 512)\n",
      "free gates tensor([[1.],\n",
      "        [1.]]) torch.Size([2, 1])\n",
      "read wei tensor([[0.2820, 0.3208, 0.1865, 0.2107],\n",
      "        [0.2839, 0.2420, 0.1920, 0.2822]]) torch.Size([2, 4])\n",
      "pre usage tensor([[1.3335e-08, 3.3045e-23, 1.9785e-24, 5.3162e-15]])\n",
      "write weit tensor([[0.0000e+00, 1.9462e-24, 9.8366e-01, 0.0000e+00]])\n",
      "retention tensor([0.5142, 0.5149, 0.6573, 0.5666])\n",
      "post usage tensor([[6.8566e-09, 1.8016e-23, 6.4656e-01, 3.0120e-15]])\n",
      "allo tensor([[5.4264e-38, 1.0000e+00, 0.0000e+00, 1.8016e-23]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[1.4324e-12, 3.9435e-09, 5.2387e-23, 2.0201e-14]])\n",
      "Alimentando paciente 3 e imagen 4 al modelo (512, 512)\n",
      "free gates tensor([[1.0000e+00],\n",
      "        [3.5691e-10]]) torch.Size([2, 1])\n",
      "read wei tensor([[2.4290e-01, 7.5664e-01, 3.4610e-08, 4.5615e-04],\n",
      "        [2.8099e-01, 2.8421e-01, 1.9782e-01, 2.3698e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[6.8566e-09, 1.8016e-23, 6.4656e-01, 3.0120e-15]])\n",
      "write weit tensor([[1.4324e-12, 3.9435e-09, 5.2387e-23, 2.0201e-14]])\n",
      "retention tensor([0.7571, 0.2434, 1.0000, 0.9995])\n",
      "post usage tensor([[5.1922e-09, 9.5969e-10, 6.4656e-01, 2.3202e-14]])\n",
      "allo tensor([[2.2267e-23, 2.3202e-14, 4.0862e-32, 1.0000e+00]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[3.8743e-30, 4.0370e-21, 7.1098e-39, 1.7399e-07]])\n",
      "Alimentando paciente 3 e imagen 23 al modelo (512, 512)\n",
      "free gates tensor([[3.5651e-11],\n",
      "        [1.0000e+00]]) torch.Size([2, 1])\n",
      "read wei tensor([[0.2747, 0.3142, 0.1518, 0.2593],\n",
      "        [0.2912, 0.2274, 0.1668, 0.3147]]) torch.Size([2, 4])\n",
      "pre usage tensor([[5.1922e-09, 9.5969e-10, 6.4656e-01, 2.3202e-14]])\n",
      "write weit tensor([[3.8743e-30, 4.0370e-21, 7.1098e-39, 1.7399e-07]])\n",
      "retention tensor([0.7088, 0.7726, 0.8332, 0.6853])\n",
      "post usage tensor([[3.6805e-09, 7.4147e-10, 5.3873e-01, 1.1924e-07]])\n",
      "allo tensor([[7.4147e-10, 1.0000e+00, 1.5010e-25, 2.7290e-18]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[0.0034, 0.0021, 0.0012, 0.0058]])\n",
      "Alimentando paciente 3 e imagen 3 al modelo (512, 512)\n",
      "free gates tensor([[1.0000e+00],\n",
      "        [1.8508e-09]]) torch.Size([2, 1])\n",
      "read wei tensor([[8.0845e-05, 4.4768e-03, 9.9543e-01, 1.7229e-05],\n",
      "        [2.7087e-01, 2.6663e-01, 2.6761e-01, 1.9488e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[3.6805e-09, 7.4147e-10, 5.3873e-01, 1.1924e-07]])\n",
      "write weit tensor([[0.0034, 0.0021, 0.0012, 0.0058]])\n",
      "retention tensor([0.9999, 0.9955, 0.0046, 1.0000])\n",
      "post usage tensor([[0.0034, 0.0021, 0.0025, 0.0058]])\n",
      "allo tensor([[5.1861e-06, 9.9789e-01, 2.1039e-03, 1.7770e-08]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[6.8444e-13, 5.2002e-08, 1.0968e-10, 1.4140e-11]])\n",
      "Alimentando paciente 3 e imagen 19 al modelo (512, 512)\n",
      "free gates tensor([[9.9971e-01],\n",
      "        [6.7437e-07]]) torch.Size([2, 1])\n",
      "read wei tensor([[0.2572, 0.3230, 0.2306, 0.1892],\n",
      "        [0.2852, 0.2544, 0.1863, 0.2741]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0.0034, 0.0021, 0.0025, 0.0058]])\n",
      "write weit tensor([[6.8444e-13, 5.2002e-08, 1.0968e-10, 1.4140e-11]])\n",
      "retention tensor([0.7429, 0.6771, 0.7694, 0.8108])\n",
      "post usage tensor([[0.0026, 0.0014, 0.0019, 0.0047]])\n",
      "allo tensor([[2.7044e-06, 9.9857e-01, 1.4254e-03, 6.8857e-09]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[2.7007e-06, 9.9721e-01, 1.4235e-03, 6.8764e-09]])\n",
      "Alimentando paciente 3 e imagen 5 al modelo (512, 512)\n",
      "free gates tensor([[1.0000e+00],\n",
      "        [4.4595e-08]]) torch.Size([2, 1])\n",
      "read wei tensor([[9.8557e-01, 2.0406e-07, 2.4780e-04, 1.4183e-02],\n",
      "        [2.2870e-01, 1.5400e-01, 3.9834e-01, 2.1895e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0.0026, 0.0014, 0.0019, 0.0047]])\n",
      "write weit tensor([[2.7007e-06, 9.9721e-01, 1.4235e-03, 6.8764e-09]])\n",
      "retention tensor([0.0144, 1.0000, 0.9998, 0.9858])\n",
      "post usage tensor([[3.6861e-05, 9.9722e-01, 3.3185e-03, 4.6514e-03]])\n",
      "allo tensor([[9.9996e-01, 1.5827e-12, 3.6739e-05, 1.2175e-07]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[9.8495e-01, 1.5589e-12, 3.6188e-05, 1.1993e-07]])\n",
      "Alimentando paciente 3 e imagen 9 al modelo (512, 512)\n",
      "free gates tensor([[0.5334],\n",
      "        [0.9993]]) torch.Size([2, 1])\n",
      "read wei tensor([[0.1796, 0.1486, 0.2456, 0.4261],\n",
      "        [0.1953, 0.1516, 0.3035, 0.3496]]) torch.Size([2, 4])\n",
      "pre usage tensor([[3.6861e-05, 9.9722e-01, 3.3185e-03, 4.6514e-03]])\n",
      "write weit tensor([[9.8495e-01, 1.5589e-12, 3.6188e-05, 1.1993e-07]])\n",
      "retention tensor([0.7278, 0.7812, 0.6054, 0.5027])\n",
      "post usage tensor([[0.7168, 0.7791, 0.0020, 0.0023]])\n",
      "allo tensor([[1.3449e-06, 7.5212e-07, 9.9797e-01, 2.0262e-03]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[0.0326, 0.0320, 0.6000, 0.0191]])\n",
      "Alimentando paciente 3 e imagen 10 al modelo (512, 512)\n",
      "free gates tensor([[1.0000],\n",
      "        [1.0000]]) torch.Size([2, 1])\n",
      "read wei tensor([[1.0918e-07, 2.0736e-10, 7.0837e-01, 2.9163e-01],\n",
      "        [2.3974e-01, 2.3104e-01, 3.1543e-01, 2.1380e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0.7168, 0.7791, 0.0020, 0.0023]])\n",
      "write weit tensor([[0.0326, 0.0320, 0.6000, 0.0191]])\n",
      "retention tensor([0.7603, 0.7690, 0.1996, 0.5569])\n",
      "post usage tensor([[0.5520, 0.6045, 0.1199, 0.0119]])\n",
      "allo tensor([[6.4170e-04, 3.1269e-04, 1.0510e-02, 9.8806e-01]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[0.2389, 0.2515, 0.1798, 0.3140]])\n",
      "Alimentando paciente 3 e imagen 2 al modelo (512, 512)\n",
      "free gates tensor([[1.0000],\n",
      "        [0.0083]]) torch.Size([2, 1])\n",
      "read wei tensor([[9.0348e-10, 1.9575e-14, 1.0000e+00, 1.8175e-06],\n",
      "        [2.1783e-01, 2.0903e-01, 2.8228e-01, 2.9086e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0.5520, 0.6045, 0.1199, 0.0119]])\n",
      "write weit tensor([[0.2389, 0.2515, 0.1798, 0.3140]])\n",
      "retention tensor([9.9819e-01, 9.9826e-01, 2.3786e-06, 9.9758e-01])\n",
      "post usage tensor([[6.5782e-01, 7.0274e-01, 6.6165e-07, 3.2143e-01]])\n",
      "allo tensor([[7.2774e-08, 4.1587e-08, 1.0000e+00, 4.4897e-07]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[3.5620e-08, 7.4925e-09, 1.2724e-03, 1.6529e-09]])\n",
      "Alimentando paciente 3 e imagen 16 al modelo (512, 512)\n",
      "free gates tensor([[1.0000],\n",
      "        [0.5313]]) torch.Size([2, 1])\n",
      "read wei tensor([[0.1138, 0.0793, 0.4383, 0.3686],\n",
      "        [0.2363, 0.1989, 0.3178, 0.2471]]) torch.Size([2, 4])\n",
      "pre usage tensor([[6.5782e-01, 7.0274e-01, 6.6165e-07, 3.2143e-01]])\n",
      "write weit tensor([[3.5620e-08, 7.4925e-09, 1.2724e-03, 1.6529e-09]])\n",
      "retention tensor([0.7749, 0.8235, 0.4669, 0.5485])\n",
      "post usage tensor([[0.5098, 0.5787, 0.0006, 0.1763]])\n",
      "allo tensor([[5.1370e-05, 2.2505e-05, 9.9941e-01, 4.8955e-04]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[4.9135e-11, 9.9171e-12, 1.5702e-07, 8.3379e-11]])\n",
      "Alimentando paciente 3 e imagen 22 al modelo (512, 512)\n",
      "free gates tensor([[0.9999],\n",
      "        [0.9999]]) torch.Size([2, 1])\n",
      "read wei tensor([[5.6676e-03, 2.7884e-04, 9.9143e-01, 2.6218e-03],\n",
      "        [2.2363e-01, 2.0348e-01, 2.8988e-01, 2.8301e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[0.5098, 0.5787, 0.0006, 0.1763]])\n",
      "write weit tensor([[4.9135e-11, 9.9171e-12, 1.5702e-07, 8.3379e-11]])\n",
      "retention tensor([0.7720, 0.7963, 0.0062, 0.7151])\n",
      "post usage tensor([[3.9353e-01, 4.6082e-01, 3.6746e-06, 1.2608e-01]])\n",
      "allo tensor([[2.8098e-07, 9.8308e-08, 1.0000e+00, 3.2113e-06]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[0.2760, 0.2820, 0.2112, 0.1875]])\n",
      "Alimentando paciente 3 e imagen 8 al modelo (512, 512)\n",
      "free gates tensor([[8.3607e-01],\n",
      "        [3.6556e-05]]) torch.Size([2, 1])\n",
      "read wei tensor([[5.1710e-06, 5.7597e-08, 9.9805e-01, 1.9446e-03],\n",
      "        [2.2902e-01, 2.2045e-01, 2.7805e-01, 2.7248e-01]]) torch.Size([2, 4])\n",
      "pre usage tensor([[3.9353e-01, 4.6082e-01, 3.6746e-06, 1.2608e-01]])\n",
      "write weit tensor([[0.2760, 0.2820, 0.2112, 0.1875]])\n",
      "retention tensor([1.0000, 1.0000, 0.1656, 0.9984])\n",
      "post usage tensor([[0.5609, 0.6129, 0.0350, 0.2895]])\n",
      "allo tensor([[0.0044, 0.0022, 0.9650, 0.0248]])\n",
      "-------------------------------------------------\n",
      "write weighting tensor([[0.0037, 0.0018, 0.8026, 0.0207]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b866ddf38a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagnostico_hemorragia_aproximado\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor_diagnostico_hemorragia_paciente\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlast_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch_challenge/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 1:\n",
    "            break\n",
    "            \n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente = imagenes_paciente[indice]\n",
    "            \n",
    "            if imagen_paciente.shape != (512,512):\n",
    "                #TODO: tread different image sizes with reshaping, resizing(or other ideas)\n",
    "                continue\n",
    "                \n",
    "            tensor_imagen_paciente =  torch.unsqueeze(\n",
    "                torch.unsqueeze( torch.Tensor(imagen_paciente),dim=0),dim=1).to(device)\n",
    "            \n",
    "            print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_hemorragia_aproximado = dnc_model(tensor_imagen_paciente)\n",
    "            \n",
    "            loss = criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente,last_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if last_image:\n",
    "                print(loss.cpu().data,diagnostico_hemorragia_aproximado.cpu().data)\n",
    "                \n",
    "            conteo_pacientes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[1],\n",
    "        [2]]) \n",
    "b = torch.Tensor([[6,7,8,9],\n",
    "        [2,3,4,5]]) \n",
    "\n",
    "print(b.size())\n",
    "\n",
    "(a*b).prod(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: averiguar por que salen 6 tensores de parametros si solo se han declarado 3(al momento de correr lap rueba)\n",
    "train_parmams = list(dnc_model.named_parameters())\n",
    "\n",
    "for train_param in train_parmams:\n",
    "    print(train_param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnc_model.write_strenght.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta (por detallar)\n",
    "* Calcular memory retention vector(con los free gates)\n",
    "* L temporal link matrix\n",
    "* u_t usage vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "* Normalizar  el allocation weighitng con sofmax(en la primera iteración asigna todo el peso a la primera posición de memoria)\n",
    "* Usar arquitectura similar a dueling network o inception para tener 2 caminos en las entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

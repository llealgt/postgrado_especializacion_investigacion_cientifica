{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.15, Latest is 1.1.17</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pixiedust\n",
    "from torchvision import transforms,datasets,models\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"../datos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos  = pd.read_excel(DATA_DIRECTORY+\"RESUMEN TAC CEREBRALES.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario cuya llave es el id de paciente y el valor una lista \n",
    "# donde cada elemento de la lista es la matriz de una i\n",
    "diccionario_imagenes_pacientes = dict()\n",
    "\n",
    "for paciente in diagnosticos.paciente:\n",
    "    directorio_paciente = DATA_DIRECTORY+\"paciente_\"+str(paciente)\n",
    "    archivos_paciente = os.listdir(directorio_paciente)\n",
    "    \n",
    "    lista_imagenes_paciente = []\n",
    "    for archivo in archivos_paciente:\n",
    "        if archivo.endswith(\".jpg\"):\n",
    "            imagen = mpimg.imread(directorio_paciente+\"/\"+archivo)\n",
    "            lista_imagenes_paciente.append(imagen)\n",
    "            \n",
    "    diccionario_imagenes_pacientes[paciente] = lista_imagenes_paciente\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos y arquitecturas\n",
    "### Arquitecturas experimental  DNC\n",
    "* Alimentamos al modelo imagen por imagen y se presenta un solo diagnostico por paciente\n",
    "* El controller de la DNC esta compuesto por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_OUTPUT_SIZE = 128\n",
    "READ_HEADS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "class ConvController(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,4,kernel_size=3,stride=1)\n",
    "        self.fc1  =  torch.nn.Linear(262144,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        h = self.conv1(x)\n",
    "        \n",
    "        #flatten\n",
    "        h =  x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        h =  self.fc1(h)\n",
    "        \n",
    "        return h #h_t in my txt\n",
    "    \n",
    "class Controller(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_controller = ConvController()\n",
    "        self.fc1 = torch.nn.Linear(10,CONTROLLER_OUTPUT_SIZE)\n",
    "        self.fc2 = torch.nn.Linear(2*CONTROLLER_OUTPUT_SIZE,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "    def forward(self,x,read_vectors):\n",
    "        h_conv = self.conv_controller(x)\n",
    "        h_read_vectors = self.fc1(read_vectors)\n",
    "        \n",
    "        h_t = torch.cat((h_conv,h_read_vectors),dim=1)\n",
    "        \n",
    "        h_t =  torch.relu( h_t)\n",
    "        h_t =  self.fc2(h_t) \n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "#TODO: cordar por que en algun momento le puse bias = False a los pesos del vector de salida de la DNC\n",
    "\n",
    "\n",
    "class DNC(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,controller,memory_size = (10,10),read_heads = 1,device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.controller = controller\n",
    "        self.device = device\n",
    "        self.N = memory_size[0] # number of memory locations\n",
    "        self.W = memory_size[1] # word size of the memory \n",
    "        self.R = read_heads # number of read heads\n",
    "        self.WS = 1 #not in the paper(they use 1), but used as a parametrizable number of write heads for further experiments\n",
    "        self.interface_vector_size = (self.W*self.R) + (self.W*self.WS) + (2*self.W) + (5*self.R) + 3\n",
    "        \n",
    "        # inicialization st to random just for testing, remember to put on zeros\n",
    "        #self.memory_matrix = self.memory_matrix =  nn.Parameter(torch.zeros(size=memory_size),requires_grad= False) \n",
    "        \n",
    "        #1024 es el tamaño del vector de salida del controlador, 1 es el tamaño de salida de la dnc\n",
    "        self.output_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,1,bias=True) #W_y \n",
    "        self.interface_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,self.interface_vector_size,bias=True) #W_ξ\n",
    "        self.read_vectors_to_output_linear = torch.nn.Linear(self.R*self.W,1,bias = True) #W_r in my txt\n",
    "        \n",
    "        self.read_keys = torch.Tensor(size=(self.R,self.W)).requires_grad_(False) # k_r in my txt\n",
    "        self.read_strenghts = torch.Tensor(size=(self.R,1)).requires_grad_(False) #β_r\n",
    "        \n",
    "        #self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(False).to(device) #r_w\n",
    "        \n",
    "        self.write_key = torch.Tensor(size=(1,self.W)).requires_grad_(False) # k_w in my txt\n",
    "        self.write_strenght = torch.Tensor(size=(1,1)).requires_grad_(False) # β_w\n",
    "        \n",
    "        #self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) # w_w\n",
    "        \n",
    "        #self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) #u_t\n",
    "        \n",
    "        self.memory_matrix_ones = torch.Tensor(torch.ones(size=memory_size)).requires_grad_(True).to(device) #E on paper\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def forward(self,x,read_vectors):\n",
    "        \n",
    "        h_t = self.controller(x,read_vectors) #controller output called ht in the paper\n",
    "        \n",
    "        output_vector = self.output_vector_linear(h_t) # called Vt in the paper(υ=Wy[h1;...;hL]) v_o_t in my txt\n",
    "        interface_vector = self.interface_vector_linear(h_t).data #called ξt(ksi) in the paper ,ξ_t in my txt\n",
    "        \n",
    "        self.read_keys.data = interface_vector[0,0:self.R*self.W].view((self.R,self.W)) #k_r in my txt\n",
    "        \n",
    "        #clamp temporary added because the exp was returning inf  values\n",
    "        read_strenghts =  torch.clamp( interface_vector[0,self.R*self.W:self.R*self.W+self.R].view((self.R,1)),max=85)\n",
    "        self.read_strenghts.data = self.oneplus(read_strenghts) #β_r\n",
    "        \n",
    "        self.write_key.data = interface_vector[0,self.R*self.W+self.R:self.R*self.W+self.R+self.W].view((1,self.W)) # k_w\n",
    "        \n",
    "        write_strenght = torch.clamp(interface_vector[:,self.R*self.W+self.R+self.W:self.R*self.W+self.R+self.W + 1].view((1,1)),max=85)\n",
    "        self.write_strenght.data = self.oneplus(write_strenght) #β_w\n",
    "        \n",
    "        erase_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1: self.R*self.W+self.R+self.W + 1 + self.W].view((1,self.W))\n",
    "        erase_vector = torch.sigmoid(erase_vector) #e_t\n",
    "        \n",
    "        write_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1 + self.W:self.R*self.W+self.R+self.W + 1 + 2*self.W].view((1,self.W)) #v_t\n",
    "        \n",
    "        free_gates  =  interface_vector[0,self.R*self.W+self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W].view((self.R,1)) #f_t\n",
    "        free_gates =   torch.sigmoid(free_gates)\n",
    "        \n",
    "        allocation_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1]\n",
    "        allocation_gate = torch.sigmoid(allocation_gate)\n",
    "        \n",
    "        write_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+2]\n",
    "        write_gate = torch.sigmoid( write_gate)\n",
    "        \n",
    "        \n",
    "        # Escritura\n",
    "        # TODO: verificar y/o experimentar si el ordern es :primero escribir y luego leer de la memoria(asi parece en el pazper)\n",
    "        retention_vector = (1.0 - free_gates * self.read_weighting).prod(dim=0)\n",
    "        self.usage_vector.data = (self.usage_vector +self.write_weighting - (self.usage_vector *self.write_weighting))*retention_vector #u_t\n",
    "        allocation_weighting = self.calc_allocation_weighting(self.usage_vector)\n",
    "        write_content_weighting = self.content_lookup(self.memory_matrix,self.write_key,self.write_strenght)\n",
    "\n",
    "        self.write_weighting.data =  write_gate*(  \n",
    "            (allocation_gate * allocation_weighting) +  ((1- allocation_gate)*write_content_weighting))\n",
    "        \n",
    "        new_memory_matrix = self.memory_matrix*(self.memory_matrix_ones - torch.matmul(self.write_weighting.t(),erase_vector)) + torch.matmul(self.write_weighting.t(),write_vector)\n",
    "        \n",
    "        self.memory_matrix.data = new_memory_matrix\n",
    "        \n",
    "        # read by content weithing(attention by similarity)\n",
    "        read_content_weighting = self.content_lookup(self.memory_matrix,self.read_keys,self.read_strenghts)\n",
    "        \n",
    "        #read weithing is a combination of reading modes,TODO:add temporal attention not just by similarity\n",
    "        self.read_weighting.data = read_content_weighting\n",
    "        \n",
    "        read_vectors = torch.matmul(self.read_weighting,self.memory_matrix).view((1,self.R*self.W)) #r in my txt\n",
    "        read_heads_to_output = self.read_vectors_to_output_linear(read_vectors) #v_r_t in my t xt\n",
    "        \n",
    "        #TODO: experiment and decide if maintain sigmoid\n",
    "        y_t = torch.sigmoid(output_vector + read_heads_to_output)\n",
    "        return y_t,read_vectors\n",
    "    \n",
    "    def oneplus(self,x):\n",
    "        # apply oneplus operation to a tensor to constrain it's elements to [1,inf)\n",
    "        #TODO: check numerical statiliby as exp is returning inf for numbers like 710,emporary added clamp to 85\n",
    "        return torch.log(1+torch.exp(x)) + 1\n",
    "    \n",
    "    def content_lookup(self,matrix,keys,strengths):\n",
    "        # returns a probability distribution over the memory locations \n",
    "        # with higher probability to memory locations with bigger similarity to the keys\n",
    "        # bigger strenght make more aggresive distributions ,for example a distribution (0.2,0.3,0.5) with\n",
    "        # bigger strenght becomes (0.1,0.12,0.78)\n",
    "        # returns tensor of shape (read keys,memory size) = (R,N)\n",
    "        keys_norm =  torch.sqrt(torch.sum(keys**2,dim=1).unsqueeze(dim=1))\n",
    "        matrix_norm = torch.sqrt(torch.sum(matrix**2,dim=1))\n",
    "        norms_multiplication = keys_norm*matrix_norm\n",
    "        # calc cosine similarity between keys and memory locations(1e-6 is used avoiding div by 0)\n",
    "        divide_zero_prevent_factor = torch.zeros_like(norms_multiplication).add_(1e-6)\n",
    "        cosine_similarity = torch.matmul(keys,matrix.t())/(torch.max(norms_multiplication,divide_zero_prevent_factor))\n",
    "        \n",
    "        # do a \"strenght\" softmax to calculate the probability distribution\n",
    "        numerator = torch.exp(cosine_similarity*strengths)\n",
    "        denominator = numerator.sum(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        distribution = numerator/denominator\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def calc_allocation_weighting(self,usage_vector):\n",
    "        #print(\"usage vector\",usage_vector)\n",
    "        _,free_list = torch.topk(-usage_vector,self.N,dim=1) #φt indices of memory locations ordered by usage\n",
    "        #print(\"free list\",free_list)\n",
    "        free_list = free_list.view(-1)\n",
    "        #print(\"reshaped free list\",free_list)\n",
    "        _,ordered_free_list =  torch.topk(-free_list,self.N)\n",
    "        ordered_free_list = ordered_free_list.view(-1)\n",
    "        #print(\"ordered free list\",ordered_free_list)\n",
    "        ordered_usage_vector = usage_vector[:,free_list]\n",
    "        #print(\"ordered usage vector\",ordered_usage_vector)\n",
    "        ordered_usage_vector_cumulative_product = torch.ones(size=(1,self.N+1)).to(device)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        #print(\"cumprod \",ordered_usage_vector.cumprod(dim=1))\n",
    "        ordered_usage_vector_cumulative_product[0,1:] = ordered_usage_vector.cumprod(dim=1)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        \n",
    "        allocation_weighting = (1 - usage_vector)*ordered_usage_vector_cumulative_product[0,ordered_free_list]\n",
    "        \n",
    "        return  allocation_weighting\n",
    "    \n",
    "    def reset(self):\n",
    "        self.memory_matrix =  torch.Tensor(torch.zeros(size=(self.N,self.W))).requires_grad_(True).to(device) \n",
    "        self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(True).to(device) #r_w\n",
    "        self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(True).to(device) # w_w\n",
    "        self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(True).to(device) #u_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "* Experimentando con DNC alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_controller = Controller()\n",
    "dnc_model = DNC(controller=conv_controller,memory_size = (5,5),read_heads=2,device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_criterion = torch.nn.BCELoss()\n",
    "def loss_function(y,y_hat,last_flag):\n",
    "    #print(y,y_hat,last_flag)\n",
    "    #base_criterion = torch.nn.BCELoss()\n",
    "    return torch.full_like(y,last_flag) * base_criterion(y,y_hat)\n",
    "    #return base_criterion(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_function\n",
    "optimizer = optim.Adam(dnc_model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "source": [
    "\n",
    "total_accuracies  = []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_predictions = []\n",
    "    epoch_real_values = []\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 99999999:\n",
    "            break\n",
    "            \n",
    "        dnc_model.reset()\n",
    "        read_vectors = torch.zeros(size=(1,dnc_model.R*dnc_model.W)).to(device)\n",
    "        \n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        losses = []\n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente = imagenes_paciente[indice]\n",
    "            \n",
    "            if imagen_paciente.shape != (512,512):\n",
    "                #TODO: tread different image sizes with reshaping, resizing(or other ideas)\n",
    "                continue\n",
    "                \n",
    "            tensor_imagen_paciente =  torch.unsqueeze(\n",
    "                torch.unsqueeze( torch.Tensor(imagen_paciente),dim=0),dim=1).to(device)\n",
    "            \n",
    "            #print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_hemorragia_aproximado,read_vectors = dnc_model(tensor_imagen_paciente,read_vectors)\n",
    "            loss = criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente,last_image)\n",
    "            \n",
    "            losses.append(loss.view((1,1)))\n",
    "            \n",
    "            if last_image:\n",
    "                y_hat = diagnostico_hemorragia_aproximado.data.cpu().numpy()[0][0]\n",
    "                y_hat_hard = float(y_hat >= 0.5)\n",
    "                epoch_predictions.append(y_hat_hard)\n",
    "                epoch_real_values.append(float(diagnostico_hemorragia_paciente))\n",
    "                \n",
    "                #print(\"--Flag ultima imagen:{} diagnostico:{} valor real{}\".format(last_image,y_hat,diagnostico_hemorragia_paciente))\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                patient_loss = torch.cat(losses).sum()\n",
    "                \n",
    "                patient_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                \n",
    "        conteo_pacientes += 1\n",
    "            \n",
    "    epoch_predictions = np.array(epoch_predictions)\n",
    "    epoch_real_values = np.array(epoch_real_values)\n",
    "    correct_predictions = epoch_predictions == epoch_real_values\n",
    "    accuracy = np.average(correct_predictions)\n",
    "    total_accuracies.append(accuracy)\n",
    "    print(\"Epoch {}: accuracy {}\".format(epoch,accuracy),epoch_predictions,epoch_real_values)\n",
    "\n",
    "print(np.average(total_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controller.conv_controller.conv1.weight\n",
      "controller.conv_controller.conv1.bias\n",
      "controller.conv_controller.fc1.weight\n",
      "controller.conv_controller.fc1.bias\n",
      "controller.fc1.weight\n",
      "controller.fc1.bias\n",
      "controller.fc2.weight\n",
      "controller.fc2.bias\n",
      "output_vector_linear.weight\n",
      "output_vector_linear.bias\n",
      "interface_vector_linear.weight\n",
      "interface_vector_linear.bias\n",
      "read_vectors_to_output_linear.weight\n",
      "read_vectors_to_output_linear.bias\n"
     ]
    }
   ],
   "source": [
    "#TODO: averiguar por que salen 6 tensores de parametros si solo se han declarado 3(al momento de correr lap rueba)\n",
    "train_parmams = list(dnc_model.named_parameters())\n",
    "\n",
    "for train_param in train_parmams:\n",
    "    print(train_param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnc_model.memory_matrix.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta (por detallar))\n",
    "* L temporal link matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM con conv\n",
    "* Experimentando con lstm alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio\n",
    "\n",
    "El vector de entrada de la lstm es un vector producido por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVNET_OUTPUT_SIZE = 1024\n",
    "CONVNET_HIDDEN_SIZE = 1024\n",
    "\n",
    "LSTM_HIDDEN_SIZE = 1024\n",
    "\n",
    "FINAL_LAYER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda2/envs/pytorch_challenge/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "architecture = 'densenet121'\n",
    "architecture_constructor = getattr(models,architecture)\n",
    "model  =  architecture_constructor(pretrained=True)\n",
    "features_size = list(model.children())[-1].in_features\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#freeze parameters so we don't backpropagete  through them\n",
    "\n",
    "#for parameter in model.parameters():\n",
    "#    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier = torch.nn.Sequential(OrderedDict([\n",
    "    (\"fc1\",torch.nn.Linear(features_size,CONVNET_OUTPUT_SIZE)),\n",
    "    #(\"relu\",torch.nn.ReLU()),\n",
    "    #(\"fc2\",torch.nn.Linear(CONVNET_HIDDEN_SIZE,CONVNET_HIDDEN_SIZE)),\n",
    "    #(\"relu2\",torch.nn.ReLU()),\n",
    "    #(\"fc3\",torch.nn.Linear(CONVNET_HIDDEN_SIZE,CONVNET_OUTPUT_SIZE))\n",
    "]))\n",
    "\n",
    "model.classifier = model_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,conv_net,lstm_layers=1):\n",
    "        super().__init__()\n",
    "        self.conv_net = conv_net\n",
    "        self.lstm = nn.LSTM(input_size= CONVNET_OUTPUT_SIZE,hidden_size = LSTM_HIDDEN_SIZE,num_layers=lstm_layers,batch_first = True)\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.lstm_hidden_size = LSTM_HIDDEN_SIZE\n",
    "        \n",
    "        self.output_linear = nn.Linear(LSTM_HIDDEN_SIZE,1)\n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        x,hidden = self.lstm(x,hidden)\n",
    "        x = x.contiguous().view(-1,self.lstm_hidden_size)\n",
    "        \n",
    "        \n",
    "        x = torch.sigmoid(self.output_linear(x))\n",
    "        \n",
    "        return x,hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        weigths =  next(self.lstm.parameters())\n",
    "        \n",
    "        \n",
    "        hidden = ( \n",
    "            weigths.new(self.lstm_layers,1,LSTM_HIDDEN_SIZE).zero_().to(device)\n",
    "        ,   weigths.new(self.lstm_layers,1,LSTM_HIDDEN_SIZE).zero_().to(device)\n",
    "                 )\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm = ConvLSTM(model,lstm_layers=3)\n",
    "conv_lstm.to(device)\n",
    "\n",
    "base_criterion = torch.nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy 0.2 loss:0.7202115058898926\n",
      "Epoch 1: accuracy 0.4 loss:0.7091841697692871\n",
      "Epoch 2: accuracy 0.6 loss:0.685421347618103\n",
      "Epoch 3: accuracy 0.6 loss:0.6858895421028137\n",
      "Epoch 4: accuracy 0.6 loss:0.6836572885513306\n",
      "Epoch 5: accuracy 0.6 loss:0.6773794293403625\n",
      "Epoch 6: accuracy 0.6 loss:0.6748774647712708\n",
      "Epoch 7: accuracy 0.6 loss:0.6741700172424316\n",
      "Epoch 8: accuracy 0.6 loss:0.6762591600418091\n",
      "Epoch 9: accuracy 0.6 loss:0.6683678030967712\n",
      "Epoch 10: accuracy 0.6 loss:0.6682066917419434\n",
      "Epoch 11: accuracy 0.6 loss:0.6652599573135376\n",
      "Epoch 12: accuracy 0.6 loss:0.6606233716011047\n",
      "Epoch 13: accuracy 0.6 loss:0.6673721075057983\n",
      "Epoch 14: accuracy 0.6 loss:0.6660476922988892\n",
      "Epoch 15: accuracy 0.6 loss:0.6823137998580933\n",
      "Epoch 16: accuracy 0.6 loss:0.6723001599311829\n",
      "Epoch 17: accuracy 0.6 loss:0.6631481647491455\n",
      "Epoch 18: accuracy 0.6 loss:0.6602168679237366\n",
      "Epoch 19: accuracy 0.6 loss:0.6536411046981812\n",
      "Epoch 20: accuracy 0.6 loss:0.6603407263755798\n",
      "Epoch 21: accuracy 0.6 loss:0.6701555848121643\n",
      "Epoch 22: accuracy 0.6 loss:0.6694320440292358\n",
      "Epoch 23: accuracy 0.6 loss:0.6655368804931641\n",
      "Epoch 24: accuracy 0.6 loss:0.6566054224967957\n",
      "Epoch 25: accuracy 0.6 loss:0.655150294303894\n",
      "Epoch 26: accuracy 0.6 loss:0.6522138714790344\n",
      "Epoch 27: accuracy 0.6 loss:0.6446203589439392\n",
      "Epoch 28: accuracy 0.6 loss:0.6561510562896729\n",
      "Epoch 29: accuracy 0.6 loss:0.6412042379379272\n",
      "Epoch 30: accuracy 0.6 loss:0.640869140625\n",
      "Epoch 31: accuracy 0.6 loss:0.635370671749115\n",
      "Epoch 32: accuracy 0.6 loss:0.6452541947364807\n",
      "Epoch 33: accuracy 0.6 loss:0.653584361076355\n",
      "Epoch 34: accuracy 0.6 loss:0.6625884771347046\n",
      "Epoch 35: accuracy 0.6 loss:0.6491988897323608\n",
      "Epoch 36: accuracy 0.6 loss:0.646154522895813\n",
      "Epoch 37: accuracy 0.6 loss:0.6372197866439819\n",
      "Epoch 38: accuracy 0.6 loss:0.6244176030158997\n",
      "Epoch 39: accuracy 0.6 loss:0.620536208152771\n",
      "Epoch 40: accuracy 0.6 loss:0.62519371509552\n",
      "Epoch 41: accuracy 0.6 loss:0.6191137433052063\n",
      "Epoch 42: accuracy 0.8 loss:0.6209990978240967\n",
      "Epoch 43: accuracy 1.0 loss:0.6181575655937195\n",
      "Epoch 44: accuracy 1.0 loss:0.6149230003356934\n",
      "Epoch 45: accuracy 0.6 loss:0.6739775538444519\n",
      "Epoch 46: accuracy 0.6 loss:0.6609118580818176\n",
      "Epoch 47: accuracy 1.0 loss:0.6163764595985413\n",
      "Epoch 48: accuracy 1.0 loss:0.5987921953201294\n",
      "Epoch 49: accuracy 1.0 loss:0.5950328707695007\n",
      "Epoch 50: accuracy 1.0 loss:0.5846935510635376\n",
      "Epoch 51: accuracy 1.0 loss:0.5746422410011292\n",
      "Epoch 52: accuracy 1.0 loss:0.5715915560722351\n",
      "Epoch 53: accuracy 1.0 loss:0.5674896240234375\n",
      "Epoch 54: accuracy 1.0 loss:0.564473032951355\n",
      "Epoch 55: accuracy 1.0 loss:0.5646360516548157\n",
      "Epoch 56: accuracy 1.0 loss:0.564349353313446\n",
      "Epoch 57: accuracy 0.8 loss:0.5905438661575317\n",
      "Epoch 58: accuracy 1.0 loss:0.5558677911758423\n",
      "Epoch 59: accuracy 1.0 loss:0.5555036067962646\n",
      "Epoch 60: accuracy 1.0 loss:0.5455140471458435\n",
      "Epoch 61: accuracy 1.0 loss:0.5449825525283813\n",
      "Epoch 62: accuracy 1.0 loss:0.537168025970459\n",
      "Epoch 63: accuracy 1.0 loss:0.5324614644050598\n",
      "Epoch 64: accuracy 1.0 loss:0.5286893248558044\n",
      "Epoch 65: accuracy 1.0 loss:0.5244770050048828\n",
      "Epoch 66: accuracy 1.0 loss:0.5203099250793457\n",
      "Epoch 67: accuracy 1.0 loss:0.5175238847732544\n",
      "Epoch 68: accuracy 1.0 loss:0.5146669745445251\n",
      "Epoch 69: accuracy 1.0 loss:0.511940598487854\n",
      "Epoch 70: accuracy 1.0 loss:0.509262204170227\n",
      "Epoch 71: accuracy 1.0 loss:0.5072506666183472\n",
      "Epoch 72: accuracy 1.0 loss:0.5048864483833313\n",
      "Epoch 73: accuracy 1.0 loss:0.5032109618186951\n",
      "Epoch 74: accuracy 1.0 loss:0.5012607574462891\n",
      "Epoch 75: accuracy 1.0 loss:0.4996175765991211\n",
      "Epoch 76: accuracy 1.0 loss:0.49819231033325195\n",
      "Epoch 77: accuracy 1.0 loss:0.496969997882843\n",
      "Epoch 78: accuracy 1.0 loss:0.495758056640625\n",
      "Epoch 79: accuracy 1.0 loss:0.49460530281066895\n",
      "Epoch 80: accuracy 1.0 loss:0.4935186505317688\n",
      "Epoch 81: accuracy 1.0 loss:0.49226388335227966\n",
      "Epoch 82: accuracy 1.0 loss:0.4910755753517151\n",
      "Epoch 83: accuracy 1.0 loss:0.49004167318344116\n",
      "Epoch 84: accuracy 1.0 loss:0.4891003966331482\n",
      "Epoch 85: accuracy 1.0 loss:0.48795557022094727\n",
      "Epoch 86: accuracy 1.0 loss:0.48677387833595276\n",
      "Epoch 87: accuracy 1.0 loss:0.48510798811912537\n",
      "Epoch 88: accuracy 1.0 loss:0.48415040969848633\n",
      "Epoch 89: accuracy 1.0 loss:0.48312681913375854\n",
      "Epoch 90: accuracy 1.0 loss:0.48243531584739685\n",
      "Epoch 91: accuracy 1.0 loss:0.48134487867355347\n",
      "Epoch 92: accuracy 1.0 loss:0.48034611344337463\n",
      "Epoch 93: accuracy 1.0 loss:0.4794146418571472\n",
      "Epoch 94: accuracy 1.0 loss:0.47867900133132935\n",
      "Epoch 95: accuracy 1.0 loss:0.47799772024154663\n",
      "Epoch 96: accuracy 1.0 loss:0.4772506654262543\n",
      "Epoch 97: accuracy 1.0 loss:0.47638779878616333\n",
      "Epoch 98: accuracy 1.0 loss:0.4757615029811859\n",
      "Epoch 99: accuracy 1.0 loss:0.4748510718345642\n",
      "Epoch 100: accuracy 1.0 loss:0.4740470051765442\n",
      "Epoch 101: accuracy 1.0 loss:0.4731271266937256\n",
      "Epoch 102: accuracy 1.0 loss:0.47226423025131226\n",
      "Epoch 103: accuracy 1.0 loss:0.47135648131370544\n",
      "Epoch 104: accuracy 1.0 loss:0.470716655254364\n",
      "Epoch 105: accuracy 1.0 loss:0.4699636399745941\n",
      "Epoch 106: accuracy 1.0 loss:0.4691123962402344\n",
      "Epoch 107: accuracy 1.0 loss:0.46829739212989807\n",
      "Epoch 108: accuracy 1.0 loss:0.4675760865211487\n",
      "Epoch 109: accuracy 1.0 loss:0.46689239144325256\n",
      "Epoch 110: accuracy 1.0 loss:0.46616387367248535\n",
      "Epoch 111: accuracy 1.0 loss:0.4655476212501526\n",
      "Epoch 112: accuracy 1.0 loss:0.4649356007575989\n",
      "Epoch 113: accuracy 1.0 loss:0.46470651030540466\n",
      "Epoch 114: accuracy 1.0 loss:0.4655703604221344\n",
      "Epoch 115: accuracy 1.0 loss:0.46863383054733276\n",
      "Epoch 116: accuracy 1.0 loss:0.4686136245727539\n",
      "Epoch 117: accuracy 1.0 loss:0.4680185317993164\n",
      "Epoch 118: accuracy 1.0 loss:0.46706700325012207\n",
      "Epoch 119: accuracy 1.0 loss:0.4658675193786621\n",
      "Epoch 120: accuracy 1.0 loss:0.46482986211776733\n",
      "Epoch 121: accuracy 1.0 loss:0.46389442682266235\n",
      "Epoch 122: accuracy 1.0 loss:0.4631202220916748\n",
      "Epoch 123: accuracy 1.0 loss:0.46258002519607544\n",
      "Epoch 124: accuracy 1.0 loss:0.4620395302772522\n",
      "Epoch 125: accuracy 1.0 loss:0.4614708423614502\n",
      "Epoch 126: accuracy 1.0 loss:0.4610597491264343\n",
      "Epoch 127: accuracy 1.0 loss:0.4605732560157776\n",
      "Epoch 128: accuracy 1.0 loss:0.4601464867591858\n",
      "Epoch 129: accuracy 1.0 loss:0.4597337245941162\n",
      "Epoch 130: accuracy 1.0 loss:0.45938271284103394\n",
      "Epoch 131: accuracy 1.0 loss:0.45901617407798767\n",
      "Epoch 132: accuracy 1.0 loss:0.4586084485054016\n",
      "Epoch 133: accuracy 1.0 loss:0.4581824243068695\n",
      "Epoch 134: accuracy 1.0 loss:0.45766615867614746\n",
      "Epoch 135: accuracy 1.0 loss:0.4572877287864685\n",
      "Epoch 136: accuracy 1.0 loss:0.4568626880645752\n",
      "Epoch 137: accuracy 1.0 loss:0.4564453661441803\n",
      "Epoch 138: accuracy 1.0 loss:0.4560144543647766\n",
      "Epoch 139: accuracy 1.0 loss:0.4555814862251282\n",
      "Epoch 140: accuracy 1.0 loss:0.4555140435695648\n",
      "Epoch 141: accuracy 1.0 loss:0.46460455656051636\n",
      "Epoch 142: accuracy 1.0 loss:0.4752422869205475\n",
      "Epoch 143: accuracy 1.0 loss:0.48048916459083557\n",
      "Epoch 144: accuracy 1.0 loss:0.47764062881469727\n",
      "Epoch 145: accuracy 1.0 loss:0.4754965901374817\n",
      "Epoch 146: accuracy 1.0 loss:0.47525453567504883\n",
      "Epoch 147: accuracy 1.0 loss:0.47285881638526917\n",
      "Epoch 148: accuracy 1.0 loss:0.4706975817680359\n",
      "Epoch 149: accuracy 1.0 loss:0.46885770559310913\n",
      "Epoch 150: accuracy 1.0 loss:0.46778783202171326\n",
      "Epoch 151: accuracy 1.0 loss:0.468416303396225\n",
      "Epoch 152: accuracy 1.0 loss:0.471190869808197\n",
      "Epoch 153: accuracy 1.0 loss:0.47333741188049316\n",
      "Epoch 154: accuracy 1.0 loss:0.47216933965682983\n",
      "Epoch 155: accuracy 1.0 loss:0.4712253212928772\n",
      "Epoch 156: accuracy 1.0 loss:0.476823091506958\n",
      "Epoch 157: accuracy 1.0 loss:0.4787835478782654\n",
      "Epoch 158: accuracy 1.0 loss:0.47625431418418884\n",
      "Epoch 159: accuracy 1.0 loss:0.4740622639656067\n",
      "Epoch 160: accuracy 1.0 loss:0.47137561440467834\n",
      "Epoch 161: accuracy 1.0 loss:0.469425767660141\n",
      "Epoch 162: accuracy 1.0 loss:0.4673648774623871\n",
      "Epoch 163: accuracy 1.0 loss:0.4659598767757416\n",
      "Epoch 164: accuracy 1.0 loss:0.4646182060241699\n",
      "Epoch 165: accuracy 1.0 loss:0.46338748931884766\n",
      "Epoch 166: accuracy 1.0 loss:0.46229618787765503\n",
      "Epoch 167: accuracy 1.0 loss:0.4612860679626465\n",
      "Epoch 168: accuracy 1.0 loss:0.4599960744380951\n",
      "Epoch 169: accuracy 1.0 loss:0.45918741822242737\n",
      "Epoch 170: accuracy 1.0 loss:0.45843440294265747\n",
      "Epoch 171: accuracy 1.0 loss:0.4575742781162262\n",
      "Epoch 172: accuracy 1.0 loss:0.45686277747154236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173: accuracy 1.0 loss:0.45623859763145447\n",
      "Epoch 174: accuracy 1.0 loss:0.45570677518844604\n",
      "Epoch 175: accuracy 1.0 loss:0.45522230863571167\n",
      "Epoch 176: accuracy 1.0 loss:0.4548094868659973\n",
      "Epoch 177: accuracy 1.0 loss:0.45410099625587463\n",
      "Epoch 178: accuracy 1.0 loss:0.4532833695411682\n",
      "Epoch 179: accuracy 1.0 loss:0.4530586302280426\n",
      "Epoch 180: accuracy 1.0 loss:0.45271262526512146\n",
      "Epoch 181: accuracy 1.0 loss:0.45242491364479065\n",
      "Epoch 182: accuracy 1.0 loss:0.4521546959877014\n",
      "Epoch 183: accuracy 1.0 loss:0.45189303159713745\n",
      "Epoch 184: accuracy 1.0 loss:0.45164400339126587\n",
      "Epoch 185: accuracy 1.0 loss:0.4513300061225891\n",
      "Epoch 186: accuracy 1.0 loss:0.4510611891746521\n",
      "Epoch 187: accuracy 1.0 loss:0.4507792592048645\n",
      "Epoch 188: accuracy 1.0 loss:0.450503408908844\n",
      "Epoch 189: accuracy 1.0 loss:0.4502216875553131\n",
      "Epoch 190: accuracy 1.0 loss:0.4499603807926178\n",
      "Epoch 191: accuracy 1.0 loss:0.4497506022453308\n",
      "Epoch 192: accuracy 1.0 loss:0.44954317808151245\n",
      "Epoch 193: accuracy 1.0 loss:0.44933396577835083\n",
      "Epoch 194: accuracy 1.0 loss:0.44914835691452026\n",
      "Epoch 195: accuracy 1.0 loss:0.44896775484085083\n",
      "Epoch 196: accuracy 1.0 loss:0.4487592279911041\n",
      "Epoch 197: accuracy 1.0 loss:0.44854649901390076\n",
      "Epoch 198: accuracy 1.0 loss:0.4483189582824707\n",
      "Epoch 199: accuracy 1.0 loss:0.44805312156677246\n",
      "[0.7202115, 0.70918417, 0.68542135, 0.68588954, 0.6836573, 0.6773794, 0.67487746, 0.67417, 0.67625916, 0.6683678, 0.6682067, 0.66525996, 0.6606234, 0.6673721, 0.6660477, 0.6823138, 0.67230016, 0.66314816, 0.66021687, 0.6536411, 0.6603407, 0.6701556, 0.66943204, 0.6655369, 0.6566054, 0.6551503, 0.6522139, 0.64462036, 0.65615106, 0.64120424, 0.64086914, 0.6353707, 0.6452542, 0.65358436, 0.6625885, 0.6491989, 0.6461545, 0.6372198, 0.6244176, 0.6205362, 0.6251937, 0.61911374, 0.6209991, 0.61815757, 0.614923, 0.67397755, 0.66091186, 0.61637646, 0.5987922, 0.5950329, 0.58469355, 0.57464224, 0.57159156, 0.5674896, 0.56447303, 0.56463605, 0.56434935, 0.59054387, 0.5558678, 0.5555036, 0.54551405, 0.54498255, 0.537168, 0.53246146, 0.5286893, 0.524477, 0.5203099, 0.5175239, 0.514667, 0.5119406, 0.5092622, 0.50725067, 0.50488645, 0.50321096, 0.50126076, 0.49961758, 0.4981923, 0.49697, 0.49575806, 0.4946053, 0.49351865, 0.49226388, 0.49107558, 0.49004167, 0.4891004, 0.48795557, 0.48677388, 0.485108, 0.4841504, 0.48312682, 0.48243532, 0.48134488, 0.4803461, 0.47941464, 0.478679, 0.47799772, 0.47725067, 0.4763878, 0.4757615, 0.47485107, 0.474047, 0.47312713, 0.47226423, 0.47135648, 0.47071666, 0.46996364, 0.4691124, 0.4682974, 0.4675761, 0.4668924, 0.46616387, 0.46554762, 0.4649356, 0.4647065, 0.46557036, 0.46863383, 0.46861362, 0.46801853, 0.467067, 0.46586752, 0.46482986, 0.46389443, 0.46312022, 0.46258003, 0.46203953, 0.46147084, 0.46105975, 0.46057326, 0.4601465, 0.45973372, 0.4593827, 0.45901617, 0.45860845, 0.45818242, 0.45766616, 0.45728773, 0.4568627, 0.45644537, 0.45601445, 0.4555815, 0.45551404, 0.46460456, 0.4752423, 0.48048916, 0.47764063, 0.4754966, 0.47525454, 0.47285882, 0.47069758, 0.4688577, 0.46778783, 0.4684163, 0.47119087, 0.4733374, 0.47216934, 0.47122532, 0.4768231, 0.47878355, 0.4762543, 0.47406226, 0.4713756, 0.46942577, 0.46736488, 0.46595988, 0.4646182, 0.4633875, 0.4622962, 0.46128607, 0.45999607, 0.45918742, 0.4584344, 0.45757428, 0.45686278, 0.4562386, 0.45570678, 0.4552223, 0.4548095, 0.454101, 0.45328337, 0.45305863, 0.45271263, 0.4524249, 0.4521547, 0.45189303, 0.451644, 0.45133, 0.4510612, 0.45077926, 0.4505034, 0.4502217, 0.44996038, 0.4497506, 0.44954318, 0.44933397, 0.44914836, 0.44896775, 0.44875923, 0.4485465, 0.44831896, 0.44805312]\n",
      "[0.2, 0.4, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.8, 1.0, 1.0, 0.6, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_accuracies  = []\n",
    "total_losses = []\n",
    "\n",
    "conv_lstm.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    \n",
    "    epoch_predictions = []\n",
    "    epoch_real_values = []\n",
    "    epoch_losses = []\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 99999999:\n",
    "            break\n",
    "        h = conv_lstm.init_hidden()\n",
    "        \n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        conv_lstm.zero_grad()\n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).view((1,1)).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        losses = []\n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            #h = tuple([each.data for each in h])\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente =  np.expand_dims(imagenes_paciente[indice],2)\n",
    "            imagen_paciente =  np.repeat(imagen_paciente,3,axis=2)\n",
    "               \n",
    "            tensor_imagen_paciente =  train_data_transforms(imagen_paciente).unsqueeze(0).to(device)\n",
    "            \n",
    "            \n",
    "            #print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_hemorragia_aproximado,h  = conv_lstm(tensor_imagen_paciente,h)\n",
    "            \n",
    "            \n",
    "            #loss = base_criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente)\n",
    "            \n",
    "            #losses.append(loss.view((1,1)))\n",
    "            \n",
    "            if last_image:\n",
    "                \n",
    "                loss =  base_criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(conv_lstm.lstm.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                y_hat = diagnostico_hemorragia_aproximado.data.cpu().numpy()[0][0]\n",
    "                y_hat_hard = float(y_hat >= 0.5)\n",
    "                epoch_predictions.append(y_hat_hard)\n",
    "                epoch_real_values.append(float(diagnostico_hemorragia_paciente))\n",
    "                \n",
    "                #print(\"--Flag ultima imagen:{} diagnostico:{} valor real{}\".format(last_image,y_hat,diagnostico_hemorragia_paciente))\n",
    "                #optimizer.zero_grad()\n",
    "                \n",
    "                #patient_loss = torch.cat(losses).mean()\n",
    "                \n",
    "                \n",
    "                #patient_loss.backward()\n",
    "                #loss.backward()\n",
    "                #nn.utils.clip_grad_norm_(conv_lstm.lstm.parameters(), 5.0)\n",
    "                #optimizer.step()\n",
    "                \n",
    "                epoch_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "                \n",
    "        conteo_pacientes += 1\n",
    "        \n",
    "            \n",
    "    epoch_predictions = np.array(epoch_predictions)\n",
    "    epoch_real_values = np.array(epoch_real_values)\n",
    "    correct_predictions = epoch_predictions == epoch_real_values\n",
    "    accuracy = np.average(correct_predictions)\n",
    "    epoch_avg_loss = np.average(epoch_losses)\n",
    "    total_losses.append(epoch_avg_loss)\n",
    "    \n",
    "    total_accuracies.append(accuracy)\n",
    "    print(\"Epoch {}: accuracy {} loss:{}\".format(epoch,accuracy,epoch_avg_loss))\n",
    "\n",
    "#print(np.average(total_accuracies))\n",
    "print(total_losses)\n",
    "print(total_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "* El mejor resultado hasta ahora ha sido no congelar pesos(entranar toda la convnet densenet121) agregandole una sola capa fully connected de salida, y 3 layers en la lstm, todas las capas con 1024 de tamaño. Lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "* Normalizar  el allocation weighitng con sofmax(en la primera iteración asigna todo el peso a la primera posición de memoria)\n",
    "* Usar arquitectura similar a dueling network o inception para tener 2 caminos en las entradas.\n",
    "* Cambiar el modelo original para leer antes que escribir y usar lo leido para sacar una predicción en ese punto en el tiempo(el modelo original lee de la memoria despues de escribir y usa la info leida en el siguiente paso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

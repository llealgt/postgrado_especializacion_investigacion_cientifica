{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.15, Latest is 1.1.17</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pixiedust\n",
    "from torchvision import transforms,datasets,models\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas y recordatorios\n",
    "\n",
    "* Por la forma en que se prepararon los datos renombre  temporalmente el paciente 120 a paciente 6(para mantener la continuidad de la muestra) y lo puse también como 6 en los diagnosticos.\n",
    "* Similar al punto anterior pero con el paciente 121 y el 7\n",
    "* Similar pero con el paciente 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fast experimentation on slow computer limit the size of the sample\n",
    "MAX_PATIENTS = 350 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"../datos/TOMOGRAFIAS CHEQUEADAS 1 - 400/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos  = pd.read_excel(DATA_DIRECTORY+\"RESUMEN TAC CEREBRALES.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paciente</th>\n",
       "      <th>hemorragia</th>\n",
       "      <th>isquemia</th>\n",
       "      <th>fractura</th>\n",
       "      <th>masa</th>\n",
       "      <th>edema</th>\n",
       "      <th>observaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>torax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>urotac revisar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no están las imágenes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paciente  hemorragia  isquemia  fractura  masa  edema  \\\n",
       "0          1         1.0       0.0       0.0   0.0    0.0   \n",
       "1          2         1.0       0.0       1.0   0.0    1.0   \n",
       "2          3         1.0       0.0       1.0   0.0    0.0   \n",
       "3          4         0.0       1.0       0.0   0.0    0.0   \n",
       "4          5         0.0       0.0       0.0   1.0    1.0   \n",
       "5          6         1.0       0.0       0.0   0.0    0.0   \n",
       "6          7         0.0       0.0       0.0   0.0    0.0   \n",
       "7          8         0.0       0.0       0.0   0.0    0.0   \n",
       "8          9         0.0       0.0       0.0   0.0    0.0   \n",
       "9         10         0.0       0.0       0.0   0.0    0.0   \n",
       "10        11         0.0       0.0       0.0   0.0    0.0   \n",
       "11        12         0.0       0.0       0.0   0.0    0.0   \n",
       "12        13         NaN       NaN       NaN   NaN    NaN   \n",
       "13        14         NaN       NaN       NaN   NaN    NaN   \n",
       "14        15         1.0       0.0       1.0   0.0    0.0   \n",
       "15        16         NaN       NaN       NaN   NaN    NaN   \n",
       "16        17         1.0       0.0       1.0   0.0    1.0   \n",
       "17        18         0.0       0.0       0.0   0.0    0.0   \n",
       "18        19         1.0       0.0       0.0   0.0    0.0   \n",
       "19        20         0.0       0.0       0.0   0.0    0.0   \n",
       "\n",
       "            observaciones  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "5                     NaN  \n",
       "6                     NaN  \n",
       "7                     NaN  \n",
       "8                     NaN  \n",
       "9                     NaN  \n",
       "10                    NaN  \n",
       "11                    NaN  \n",
       "12                  torax  \n",
       "13         urotac revisar  \n",
       "14                    NaN  \n",
       "15                abdomen  \n",
       "16                    NaN  \n",
       "17                    NaN  \n",
       "18  no están las imágenes  \n",
       "19                    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosticos.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario cuya llave es el id de paciente y el valor una lista \n",
    "# donde cada elemento de la lista es la matriz de una i\n",
    "diccionario_imagenes_pacientes = dict()\n",
    "processed_patients = 0\n",
    "\n",
    "for paciente in diagnosticos.paciente:\n",
    "    if processed_patients >= MAX_PATIENTS:\n",
    "        diagnosticos = diagnosticos.iloc[:processed_patients]\n",
    "        break\n",
    "    directorio_paciente = DATA_DIRECTORY+\"paciente_\"+str(paciente)\n",
    "    \n",
    "    # if patient directory is missing OR any of the diagnostics is null \n",
    "    #do not try to read images and delete it from diagnostics dataframe\n",
    "    if not os.path.exists(directorio_paciente) or  diagnosticos[diagnosticos.paciente == paciente].iloc[:,0:6].isnull().values.any():\n",
    "        diagnostics_row = diagnosticos[diagnosticos.paciente == paciente]\n",
    "        diagnosticos.drop(int(diagnostics_row.index.values),axis=0,inplace=True)\n",
    "        \n",
    "        continue\n",
    "    archivos_paciente = os.listdir(directorio_paciente)\n",
    "    \n",
    "    lista_imagenes_paciente = []\n",
    "    for archivo in archivos_paciente:\n",
    "        if archivo.endswith(\".jpg\"):\n",
    "            imagen = mpimg.imread(directorio_paciente+\"/\"+archivo)\n",
    "            lista_imagenes_paciente.append(imagen)\n",
    "            \n",
    "    processed_patients += 1\n",
    "            \n",
    "    diccionario_imagenes_pacientes[paciente] = lista_imagenes_paciente\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paciente</th>\n",
       "      <th>hemorragia</th>\n",
       "      <th>isquemia</th>\n",
       "      <th>fractura</th>\n",
       "      <th>masa</th>\n",
       "      <th>edema</th>\n",
       "      <th>observaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paciente  hemorragia  isquemia  fractura  masa  edema observaciones\n",
       "0          1         1.0       0.0       0.0   0.0    0.0           NaN\n",
       "1          2         1.0       0.0       1.0   0.0    1.0           NaN\n",
       "2          3         1.0       0.0       1.0   0.0    0.0           NaN\n",
       "3          4         0.0       1.0       0.0   0.0    0.0           NaN\n",
       "4          5         0.0       0.0       0.0   1.0    1.0           NaN\n",
       "5          6         1.0       0.0       0.0   0.0    0.0           NaN\n",
       "6          7         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "7          8         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "8          9         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "9         10         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "10        11         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "11        12         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "14        15         1.0       0.0       1.0   0.0    0.0           NaN\n",
       "16        17         1.0       0.0       1.0   0.0    1.0           NaN\n",
       "17        18         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "19        20         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "20        21         1.0       0.0       0.0   0.0    0.0           NaN\n",
       "21        22         1.0       0.0       1.0   0.0    1.0           NaN\n",
       "22        23         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "23        24         0.0       0.0       0.0   0.0    0.0           NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosticos.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos y arquitecturas\n",
    "### Arquitecturas experimental  DNC\n",
    "* Alimentamos al modelo imagen por imagen y se presenta un solo diagnostico por paciente\n",
    "* El controller de la DNC esta compuesto por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_OUTPUT_SIZE = 128\n",
    "READ_HEADS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "class ConvController(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,4,kernel_size=3,stride=1)\n",
    "        self.fc1  =  torch.nn.Linear(262144,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        h = self.conv1(x)\n",
    "        \n",
    "        #flatten\n",
    "        h =  x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        h =  self.fc1(h)\n",
    "        \n",
    "        return h #h_t in my txt\n",
    "    \n",
    "class Controller(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_controller = ConvController()\n",
    "        self.fc1 = torch.nn.Linear(10,CONTROLLER_OUTPUT_SIZE)\n",
    "        self.fc2 = torch.nn.Linear(2*CONTROLLER_OUTPUT_SIZE,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "    def forward(self,x,read_vectors):\n",
    "        h_conv = self.conv_controller(x)\n",
    "        h_read_vectors = self.fc1(read_vectors)\n",
    "        \n",
    "        h_t = torch.cat((h_conv,h_read_vectors),dim=1)\n",
    "        \n",
    "        h_t =  torch.relu( h_t)\n",
    "        h_t =  self.fc2(h_t) \n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "#TODO: cordar por que en algun momento le puse bias = False a los pesos del vector de salida de la DNC\n",
    "\n",
    "\n",
    "class DNC(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,controller,memory_size = (10,10),read_heads = 1,device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.controller = controller\n",
    "        self.device = device\n",
    "        self.N = memory_size[0] # number of memory locations\n",
    "        self.W = memory_size[1] # word size of the memory \n",
    "        self.R = read_heads # number of read heads\n",
    "        self.WS = 1 #not in the paper(they use 1), but used as a parametrizable number of write heads for further experiments\n",
    "        self.interface_vector_size = (self.W*self.R) + (self.W*self.WS) + (2*self.W) + (5*self.R) + 3\n",
    "        \n",
    "        # inicialization st to random just for testing, remember to put on zeros\n",
    "        #self.memory_matrix = self.memory_matrix =  nn.Parameter(torch.zeros(size=memory_size),requires_grad= False) \n",
    "        \n",
    "        #1024 es el tamaño del vector de salida del controlador, 1 es el tamaño de salida de la dnc\n",
    "        self.output_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,1,bias=True) #W_y \n",
    "        self.interface_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,self.interface_vector_size,bias=True) #W_ξ\n",
    "        self.read_vectors_to_output_linear = torch.nn.Linear(self.R*self.W,1,bias = True) #W_r in my txt\n",
    "        \n",
    "        self.read_keys = torch.Tensor(size=(self.R,self.W)).requires_grad_(False) # k_r in my txt\n",
    "        self.read_strenghts = torch.Tensor(size=(self.R,1)).requires_grad_(False) #β_r\n",
    "        \n",
    "        #self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(False).to(device) #r_w\n",
    "        \n",
    "        self.write_key = torch.Tensor(size=(1,self.W)).requires_grad_(False) # k_w in my txt\n",
    "        self.write_strenght = torch.Tensor(size=(1,1)).requires_grad_(False) # β_w\n",
    "        \n",
    "        #self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) # w_w\n",
    "        \n",
    "        #self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) #u_t\n",
    "        \n",
    "        self.memory_matrix_ones = torch.Tensor(torch.ones(size=memory_size)).requires_grad_(True).to(device) #E on paper\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def forward(self,x,read_vectors):\n",
    "        \n",
    "        h_t = self.controller(x,read_vectors) #controller output called ht in the paper\n",
    "        \n",
    "        output_vector = self.output_vector_linear(h_t) # called Vt in the paper(υ=Wy[h1;...;hL]) v_o_t in my txt\n",
    "        interface_vector = self.interface_vector_linear(h_t).data #called ξt(ksi) in the paper ,ξ_t in my txt\n",
    "        \n",
    "        self.read_keys.data = interface_vector[0,0:self.R*self.W].view((self.R,self.W)) #k_r in my txt\n",
    "        \n",
    "        #clamp temporary added because the exp was returning inf  values\n",
    "        read_strenghts =  torch.clamp( interface_vector[0,self.R*self.W:self.R*self.W+self.R].view((self.R,1)),max=85)\n",
    "        self.read_strenghts.data = self.oneplus(read_strenghts) #β_r\n",
    "        \n",
    "        self.write_key.data = interface_vector[0,self.R*self.W+self.R:self.R*self.W+self.R+self.W].view((1,self.W)) # k_w\n",
    "        \n",
    "        write_strenght = torch.clamp(interface_vector[:,self.R*self.W+self.R+self.W:self.R*self.W+self.R+self.W + 1].view((1,1)),max=85)\n",
    "        self.write_strenght.data = self.oneplus(write_strenght) #β_w\n",
    "        \n",
    "        erase_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1: self.R*self.W+self.R+self.W + 1 + self.W].view((1,self.W))\n",
    "        erase_vector = torch.sigmoid(erase_vector) #e_t\n",
    "        \n",
    "        write_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1 + self.W:self.R*self.W+self.R+self.W + 1 + 2*self.W].view((1,self.W)) #v_t\n",
    "        \n",
    "        free_gates  =  interface_vector[0,self.R*self.W+self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W].view((self.R,1)) #f_t\n",
    "        free_gates =   torch.sigmoid(free_gates)\n",
    "        \n",
    "        allocation_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1]\n",
    "        allocation_gate = torch.sigmoid(allocation_gate)\n",
    "        \n",
    "        write_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+2]\n",
    "        write_gate = torch.sigmoid( write_gate)\n",
    "        \n",
    "        \n",
    "        # Escritura\n",
    "        # TODO: verificar y/o experimentar si el ordern es :primero escribir y luego leer de la memoria(asi parece en el pazper)\n",
    "        retention_vector = (1.0 - free_gates * self.read_weighting).prod(dim=0)\n",
    "        self.usage_vector.data = (self.usage_vector +self.write_weighting - (self.usage_vector *self.write_weighting))*retention_vector #u_t\n",
    "        allocation_weighting = self.calc_allocation_weighting(self.usage_vector)\n",
    "        write_content_weighting = self.content_lookup(self.memory_matrix,self.write_key,self.write_strenght)\n",
    "\n",
    "        self.write_weighting.data =  write_gate*(  \n",
    "            (allocation_gate * allocation_weighting) +  ((1- allocation_gate)*write_content_weighting))\n",
    "        \n",
    "        new_memory_matrix = self.memory_matrix*(self.memory_matrix_ones - torch.matmul(self.write_weighting.t(),erase_vector)) + torch.matmul(self.write_weighting.t(),write_vector)\n",
    "        \n",
    "        self.memory_matrix.data = new_memory_matrix\n",
    "        \n",
    "        # read by content weithing(attention by similarity)\n",
    "        read_content_weighting = self.content_lookup(self.memory_matrix,self.read_keys,self.read_strenghts)\n",
    "        \n",
    "        #read weithing is a combination of reading modes,TODO:add temporal attention not just by similarity\n",
    "        self.read_weighting.data = read_content_weighting\n",
    "        \n",
    "        read_vectors = torch.matmul(self.read_weighting,self.memory_matrix).view((1,self.R*self.W)) #r in my txt\n",
    "        read_heads_to_output = self.read_vectors_to_output_linear(read_vectors) #v_r_t in my t xt\n",
    "        \n",
    "        #TODO: experiment and decide if maintain sigmoid\n",
    "        y_t = torch.sigmoid(output_vector + read_heads_to_output)\n",
    "        return y_t,read_vectors\n",
    "    \n",
    "    def oneplus(self,x):\n",
    "        # apply oneplus operation to a tensor to constrain it's elements to [1,inf)\n",
    "        #TODO: check numerical statiliby as exp is returning inf for numbers like 710,emporary added clamp to 85\n",
    "        return torch.log(1+torch.exp(x)) + 1\n",
    "    \n",
    "    def content_lookup(self,matrix,keys,strengths):\n",
    "        # returns a probability distribution over the memory locations \n",
    "        # with higher probability to memory locations with bigger similarity to the keys\n",
    "        # bigger strenght make more aggresive distributions ,for example a distribution (0.2,0.3,0.5) with\n",
    "        # bigger strenght becomes (0.1,0.12,0.78)\n",
    "        # returns tensor of shape (read keys,memory size) = (R,N)\n",
    "        keys_norm =  torch.sqrt(torch.sum(keys**2,dim=1).unsqueeze(dim=1))\n",
    "        matrix_norm = torch.sqrt(torch.sum(matrix**2,dim=1))\n",
    "        norms_multiplication = keys_norm*matrix_norm\n",
    "        # calc cosine similarity between keys and memory locations(1e-6 is used avoiding div by 0)\n",
    "        divide_zero_prevent_factor = torch.zeros_like(norms_multiplication).add_(1e-6)\n",
    "        cosine_similarity = torch.matmul(keys,matrix.t())/(torch.max(norms_multiplication,divide_zero_prevent_factor))\n",
    "        \n",
    "        # do a \"strenght\" softmax to calculate the probability distribution\n",
    "        numerator = torch.exp(cosine_similarity*strengths)\n",
    "        denominator = numerator.sum(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        distribution = numerator/denominator\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def calc_allocation_weighting(self,usage_vector):\n",
    "        #print(\"usage vector\",usage_vector)\n",
    "        _,free_list = torch.topk(-usage_vector,self.N,dim=1) #φt indices of memory locations ordered by usage\n",
    "        #print(\"free list\",free_list)\n",
    "        free_list = free_list.view(-1)\n",
    "        #print(\"reshaped free list\",free_list)\n",
    "        _,ordered_free_list =  torch.topk(-free_list,self.N)\n",
    "        ordered_free_list = ordered_free_list.view(-1)\n",
    "        #print(\"ordered free list\",ordered_free_list)\n",
    "        ordered_usage_vector = usage_vector[:,free_list]\n",
    "        #print(\"ordered usage vector\",ordered_usage_vector)\n",
    "        ordered_usage_vector_cumulative_product = torch.ones(size=(1,self.N+1)).to(device)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        #print(\"cumprod \",ordered_usage_vector.cumprod(dim=1))\n",
    "        ordered_usage_vector_cumulative_product[0,1:] = ordered_usage_vector.cumprod(dim=1)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        \n",
    "        allocation_weighting = (1 - usage_vector)*ordered_usage_vector_cumulative_product[0,ordered_free_list]\n",
    "        \n",
    "        return  allocation_weighting\n",
    "    \n",
    "    def reset(self):\n",
    "        self.memory_matrix =  torch.Tensor(torch.zeros(size=(self.N,self.W))).requires_grad_(True).to(device) \n",
    "        self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(True).to(device) #r_w\n",
    "        self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(True).to(device) # w_w\n",
    "        self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(True).to(device) #u_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "* Experimentando con DNC alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_controller = Controller()\n",
    "dnc_model = DNC(controller=conv_controller,memory_size = (5,5),read_heads=2,device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_criterion = torch.nn.BCELoss()\n",
    "def loss_function(y,y_hat,last_flag):\n",
    "    #print(y,y_hat,last_flag)\n",
    "    #base_criterion = torch.nn.BCELoss()\n",
    "    return torch.full_like(y,last_flag) * base_criterion(y,y_hat)\n",
    "    #return base_criterion(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_function\n",
    "optimizer = optim.Adam(dnc_model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "source": [
    "\n",
    "total_accuracies  = []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_predictions = []\n",
    "    epoch_real_values = []\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 99999999:\n",
    "            break\n",
    "            \n",
    "        dnc_model.reset()\n",
    "        read_vectors = torch.zeros(size=(1,dnc_model.R*dnc_model.W)).to(device)\n",
    "        \n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        losses = []\n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente = imagenes_paciente[indice]\n",
    "            \n",
    "            if imagen_paciente.shape != (512,512):\n",
    "                #TODO: tread different image sizes with reshaping, resizing(or other ideas)\n",
    "                continue\n",
    "                \n",
    "            tensor_imagen_paciente =  torch.unsqueeze(\n",
    "                torch.unsqueeze( torch.Tensor(imagen_paciente),dim=0),dim=1).to(device)\n",
    "            \n",
    "            #print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_hemorragia_aproximado,read_vectors = dnc_model(tensor_imagen_paciente,read_vectors)\n",
    "            loss = criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente,last_image)\n",
    "            \n",
    "            losses.append(loss.view((1,1)))\n",
    "            \n",
    "            if last_image:\n",
    "                y_hat = diagnostico_hemorragia_aproximado.data.cpu().numpy()[0][0]\n",
    "                y_hat_hard = float(y_hat >= 0.5)\n",
    "                epoch_predictions.append(y_hat_hard)\n",
    "                epoch_real_values.append(float(diagnostico_hemorragia_paciente))\n",
    "                \n",
    "                #print(\"--Flag ultima imagen:{} diagnostico:{} valor real{}\".format(last_image,y_hat,diagnostico_hemorragia_paciente))\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                patient_loss = torch.cat(losses).sum()\n",
    "                \n",
    "                patient_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                \n",
    "        conteo_pacientes += 1\n",
    "            \n",
    "    epoch_predictions = np.array(epoch_predictions)\n",
    "    epoch_real_values = np.array(epoch_real_values)\n",
    "    correct_predictions = epoch_predictions == epoch_real_values\n",
    "    accuracy = np.average(correct_predictions)\n",
    "    total_accuracies.append(accuracy)\n",
    "    print(\"Epoch {}: accuracy {}\".format(epoch,accuracy),epoch_predictions,epoch_real_values)\n",
    "\n",
    "print(np.average(total_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controller.conv_controller.conv1.weight\n",
      "controller.conv_controller.conv1.bias\n",
      "controller.conv_controller.fc1.weight\n",
      "controller.conv_controller.fc1.bias\n",
      "controller.fc1.weight\n",
      "controller.fc1.bias\n",
      "controller.fc2.weight\n",
      "controller.fc2.bias\n",
      "output_vector_linear.weight\n",
      "output_vector_linear.bias\n",
      "interface_vector_linear.weight\n",
      "interface_vector_linear.bias\n",
      "read_vectors_to_output_linear.weight\n",
      "read_vectors_to_output_linear.bias\n"
     ]
    }
   ],
   "source": [
    "#TODO: averiguar por que salen 6 tensores de parametros si solo se han declarado 3(al momento de correr lap rueba)\n",
    "train_parmams = list(dnc_model.named_parameters())\n",
    "\n",
    "for train_param in train_parmams:\n",
    "    print(train_param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnc_model.memory_matrix.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta (por detallar))\n",
    "* L temporal link matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM con conv\n",
    "* Experimentando con lstm alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio\n",
    "\n",
    "El vector de entrada de la lstm es un vector producido por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVNET_OUTPUT_SIZE = 1024\n",
    "CONVNET_HIDDEN_SIZE = 1024\n",
    "\n",
    "LSTM_HIDDEN_SIZE = 1024\n",
    "\n",
    "FINAL_LAYER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda2/envs/pytorch_challenge/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "architecture = 'densenet121'\n",
    "architecture_constructor = getattr(models,architecture)\n",
    "model  =  architecture_constructor(pretrained=True)\n",
    "features_size = list(model.children())[-1].in_features\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#freeze parameters so we don't backpropagete  through them\n",
    "layers_to_freeze = 0\n",
    "layer_num = 0\n",
    "for parameter in model.parameters():\n",
    "    if layer_num >= layers_to_freeze:\n",
    "        break\n",
    "    parameter.requires_grad = False\n",
    "        \n",
    "    layer_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier = torch.nn.Sequential(OrderedDict([\n",
    "    (\"fc1\",torch.nn.Linear(features_size,CONVNET_OUTPUT_SIZE)),\n",
    "    #(\"relu\",torch.nn.ReLU()),\n",
    "    #(\"fc2\",torch.nn.Linear(CONVNET_HIDDEN_SIZE,CONVNET_HIDDEN_SIZE)),\n",
    "    #(\"relu2\",torch.nn.ReLU()),\n",
    "    #(\"fc3\",torch.nn.Linear(CONVNET_HIDDEN_SIZE,CONVNET_OUTPUT_SIZE))\n",
    "]))\n",
    "\n",
    "model.classifier = model_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,conv_net,lstm_layers=1):\n",
    "        super().__init__()\n",
    "        self.conv_net = conv_net\n",
    "        self.lstm = nn.LSTM(input_size= CONVNET_OUTPUT_SIZE,hidden_size = LSTM_HIDDEN_SIZE,num_layers=lstm_layers,batch_first = True)\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.lstm_hidden_size = LSTM_HIDDEN_SIZE\n",
    "        \n",
    "        self.output_linear = nn.Linear(LSTM_HIDDEN_SIZE,5)\n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        x,hidden = self.lstm(x,hidden)\n",
    "        x = x.contiguous().view(-1,self.lstm_hidden_size)\n",
    "        \n",
    "        x = self.output_linear(x)\n",
    "        #x = torch.sigmoid(self.output_linear(x))\n",
    "        \n",
    "        return x,hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        weigths =  next(self.lstm.parameters())\n",
    "        \n",
    "        \n",
    "        hidden = ( \n",
    "            weigths.new(self.lstm_layers,1,LSTM_HIDDEN_SIZE).zero_().to(device)\n",
    "        ,   weigths.new(self.lstm_layers,1,LSTM_HIDDEN_SIZE).zero_().to(device)\n",
    "                 )\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya que estamos usando densenet121 transformamos los datos de entrada para que tengan el tamaño adecuado\n",
    "# y se normalicen usando los valores de media y desviación estandar del dataset usado en densenet\n",
    "train_data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm = ConvLSTM(model,lstm_layers=3)\n",
    "conv_lstm.to(device)\n",
    "\n",
    "base_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred,y_real):\n",
    "    \"for calculating the accurracy of multiple columns\"\n",
    "    assert y_pred.shape[1] == y_real.shape[1]\n",
    "    \n",
    "    num_columns = y_pred.shape[1]\n",
    "    \n",
    "    accuracies = []\n",
    "    for i in range(num_columns):\n",
    "        \n",
    "        colum_acc = accuracy_score(y_pred[:,i],y_real[:,i])\n",
    "        accuracies.append(colum_acc)\n",
    "        \n",
    "    return accuracies, np.mean(np.array(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: individual accs:[[0.9291044776119403, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.908955223880597 loss:0.5714588761329651\n",
      "Epoch 1: individual accs:[[0.9365671641791045, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9104477611940298 loss:0.5703461170196533\n",
      "Epoch 2: individual accs:[[0.9440298507462687, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9119402985074627 loss:0.5699785947799683\n",
      "Epoch 3: individual accs:[[0.9514925373134329, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9134328358208954 loss:0.5700439810752869\n",
      "Epoch 4: individual accs:[[0.9626865671641791, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9156716417910447 loss:0.5699806809425354\n",
      "[0.5714589, 0.5703461, 0.5699786, 0.570044, 0.5699807]\n",
      "[0.908955223880597, 0.9104477611940298, 0.9119402985074627, 0.9134328358208954, 0.9156716417910447]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_accuracies  = []\n",
    "total_losses = []\n",
    "\n",
    "conv_lstm.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    \n",
    "    epoch_predictions = []\n",
    "    epoch_real_values = []\n",
    "    epoch_losses = []\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 99999999:\n",
    "            break\n",
    "            \n",
    "        #TODO: this patient has many images and creates an out of memory error\n",
    "        if  len(diccionario_imagenes_pacientes.get(paciente)) >= 50:\n",
    "            continue\n",
    "            \n",
    "        h = conv_lstm.init_hidden()\n",
    "        \n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        conv_lstm.zero_grad()\n",
    "        \n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        vector_diagnostico_paciente = np.array(diagnosticos[diagnosticos.paciente==paciente][[\"hemorragia\",\"isquemia\",\"fractura\",\"masa\",\"edema\"]])\n",
    "        tensor_diagnostico_paciente = torch.Tensor(vector_diagnostico_paciente).view((1,5)).to(device)\n",
    "        \n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).view((1,1)).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        losses = []\n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            #h = tuple([each.data for each in h])\n",
    "            #print(paciente,indice)\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente =  np.expand_dims(imagenes_paciente[indice],2)\n",
    "            imagen_paciente =  np.repeat(imagen_paciente,3,axis=2)\n",
    "               \n",
    "            tensor_imagen_paciente =  train_data_transforms(imagen_paciente).unsqueeze(0).to(device)\n",
    "            \n",
    "            \n",
    "            #print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_aproximado,h  = conv_lstm(tensor_imagen_paciente,h)\n",
    "            prob_diagnostico_aproximado = torch.sigmoid(diagnostico_aproximado)\n",
    "            diagnostico_hemorragia_aproximado = diagnostico_aproximado[:,0]\n",
    "            \n",
    "            \n",
    "            #loss = base_criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente)\n",
    "            \n",
    "            #losses.append(loss.view((1,1)))\n",
    "            \n",
    "            if last_image:\n",
    "                \n",
    "                loss =  base_criterion(diagnostico_aproximado,tensor_diagnostico_paciente)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(conv_lstm.lstm.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                vector_y_hat_hard = prob_diagnostico_aproximado >= 0.5\n",
    "                \n",
    "                #print(torch.sigmoid(diagnostico_aproximado).data,tensor_diagnostico_paciente.data)\n",
    "                y_hat = diagnostico_hemorragia_aproximado.data.cpu().numpy()[0]\n",
    "                y_hat_hard = float(y_hat >= 0.5)\n",
    "                \n",
    "                epoch_predictions.append(vector_y_hat_hard.data.cpu().numpy()[0])\n",
    "                epoch_real_values.append(vector_diagnostico_paciente[0])\n",
    "                \n",
    "                \n",
    "                #print(\"--Flag ultima imagen:{} diagnostico:{} valor real{}\".format(last_image,y_hat,diagnostico_hemorragia_paciente))\n",
    "                #optimizer.zero_grad()\n",
    "                \n",
    "                #patient_loss = torch.cat(losses).mean()\n",
    "                \n",
    "                \n",
    "                #patient_loss.backward()\n",
    "                #loss.backward()\n",
    "                #nn.utils.clip_grad_norm_(conv_lstm.lstm.parameters(), 5.0)\n",
    "                #optimizer.step()\n",
    "                \n",
    "                epoch_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "                \n",
    "        conteo_pacientes += 1\n",
    "        \n",
    "            \n",
    "    #epoch_predictions = np.array(epoch_predictions)\n",
    "    #epoch_real_values = np.array(epoch_real_values)\n",
    "    #correct_predictions = epoch_predictions == epoch_real_values\n",
    "    #accuracy = np.average(correct_predictions)\n",
    "    accuracies,average_accuracy = calc_accuracy(np.array(epoch_predictions),np.array(epoch_real_values))\n",
    "    \n",
    "    epoch_avg_loss = np.average(epoch_losses)\n",
    "    total_losses.append(epoch_avg_loss)\n",
    "    \n",
    "    total_accuracies.append(average_accuracy)\n",
    "    print(\"Epoch {}: individual accs:[{}] avg accuracy {} loss:{}\".format(epoch,accuracies,average_accuracy,epoch_avg_loss))\n",
    "\n",
    "#print(np.average(total_accuracies))\n",
    "print(total_losses)\n",
    "print(total_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "* El mejor resultado hasta ahora ha sido no congelar pesos(entranar toda la convnet densenet121) agregandole una sola capa fully connected de salida, y 3 layers en la lstm, todas las capas con 1024 de tamaño. Lr = 0.001.\n",
    "* Congelando las primeras 50 capas de la convnet converge alrededor de los 40 epochs(pero sigue bajando) con la misma configuración qeu el resultado 1.\n",
    "* Misma arquitectura pero congelando 100 capas de la convnet(y agregando una nueva muestra de pacientes de 3 ) converge alrededor de los 25 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "* Normalizar  el allocation weighitng con sofmax(en la primera iteración asigna todo el peso a la primera posición de memoria)\n",
    "* Usar arquitectura similar a dueling network o inception para tener 2 caminos en las entradas.\n",
    "* Cambiar el modelo original para leer antes que escribir y usar lo leido para sacar una predicción en ese punto en el tiempo(el modelo original lee de la memoria despues de escribir y usa la info leida en el siguiente paso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

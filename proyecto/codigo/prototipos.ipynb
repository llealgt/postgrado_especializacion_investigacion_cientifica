{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.15, Latest is 1.1.17</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pixiedust\n",
    "from torchvision import transforms,datasets,models\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas y recordatorios\n",
    "\n",
    "* Por la forma en que se prepararon los datos renombre  temporalmente el paciente 120 a paciente 6(para mantener la continuidad de la muestra) y lo puse también como 6 en los diagnosticos.\n",
    "* Similar al punto anterior pero con el paciente 121 y el 7\n",
    "* Similar pero con el paciente 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fast experimentation on slow computer limit the size of the sample\n",
    "MAX_PATIENTS = 350 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"../datos/TOMOGRAFIAS CHEQUEADAS 1 - 400/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosticos  = pd.read_excel(DATA_DIRECTORY+\"RESUMEN TAC CEREBRALES.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paciente</th>\n",
       "      <th>hemorragia</th>\n",
       "      <th>isquemia</th>\n",
       "      <th>fractura</th>\n",
       "      <th>masa</th>\n",
       "      <th>edema</th>\n",
       "      <th>observaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>torax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>urotac revisar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abdomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no están las imágenes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paciente  hemorragia  isquemia  fractura  masa  edema  \\\n",
       "0          1         1.0       0.0       0.0   0.0    0.0   \n",
       "1          2         1.0       0.0       1.0   0.0    1.0   \n",
       "2          3         1.0       0.0       1.0   0.0    0.0   \n",
       "3          4         0.0       1.0       0.0   0.0    0.0   \n",
       "4          5         0.0       0.0       0.0   1.0    1.0   \n",
       "5          6         1.0       0.0       0.0   0.0    0.0   \n",
       "6          7         0.0       0.0       0.0   0.0    0.0   \n",
       "7          8         0.0       0.0       0.0   0.0    0.0   \n",
       "8          9         0.0       0.0       0.0   0.0    0.0   \n",
       "9         10         0.0       0.0       0.0   0.0    0.0   \n",
       "10        11         0.0       0.0       0.0   0.0    0.0   \n",
       "11        12         0.0       0.0       0.0   0.0    0.0   \n",
       "12        13         NaN       NaN       NaN   NaN    NaN   \n",
       "13        14         NaN       NaN       NaN   NaN    NaN   \n",
       "14        15         1.0       0.0       1.0   0.0    0.0   \n",
       "15        16         NaN       NaN       NaN   NaN    NaN   \n",
       "16        17         1.0       0.0       1.0   0.0    1.0   \n",
       "17        18         0.0       0.0       0.0   0.0    0.0   \n",
       "18        19         1.0       0.0       0.0   0.0    0.0   \n",
       "19        20         0.0       0.0       0.0   0.0    0.0   \n",
       "\n",
       "            observaciones  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "5                     NaN  \n",
       "6                     NaN  \n",
       "7                     NaN  \n",
       "8                     NaN  \n",
       "9                     NaN  \n",
       "10                    NaN  \n",
       "11                    NaN  \n",
       "12                  torax  \n",
       "13         urotac revisar  \n",
       "14                    NaN  \n",
       "15                abdomen  \n",
       "16                    NaN  \n",
       "17                    NaN  \n",
       "18  no están las imágenes  \n",
       "19                    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosticos.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario cuya llave es el id de paciente y el valor una lista \n",
    "# donde cada elemento de la lista es la matriz de una i\n",
    "diccionario_imagenes_pacientes = dict()\n",
    "processed_patients = 0\n",
    "\n",
    "for paciente in diagnosticos.paciente:\n",
    "    if processed_patients >= MAX_PATIENTS:\n",
    "        diagnosticos = diagnosticos.iloc[:processed_patients]\n",
    "        break\n",
    "    directorio_paciente = DATA_DIRECTORY+\"paciente_\"+str(paciente)\n",
    "    \n",
    "    # if patient directory is missing OR any of the diagnostics is null \n",
    "    #do not try to read images and delete it from diagnostics dataframe\n",
    "    if not os.path.exists(directorio_paciente) or  diagnosticos[diagnosticos.paciente == paciente].iloc[:,0:6].isnull().values.any():\n",
    "        diagnostics_row = diagnosticos[diagnosticos.paciente == paciente]\n",
    "        diagnosticos.drop(int(diagnostics_row.index.values),axis=0,inplace=True)\n",
    "        \n",
    "        continue\n",
    "    archivos_paciente = os.listdir(directorio_paciente)\n",
    "    \n",
    "    lista_imagenes_paciente = []\n",
    "    for archivo in archivos_paciente:\n",
    "        if archivo.endswith(\".jpg\"):\n",
    "            imagen = mpimg.imread(directorio_paciente+\"/\"+archivo)\n",
    "            lista_imagenes_paciente.append(imagen)\n",
    "            \n",
    "    processed_patients += 1\n",
    "            \n",
    "    diccionario_imagenes_pacientes[paciente] = lista_imagenes_paciente\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paciente</th>\n",
       "      <th>hemorragia</th>\n",
       "      <th>isquemia</th>\n",
       "      <th>fractura</th>\n",
       "      <th>masa</th>\n",
       "      <th>edema</th>\n",
       "      <th>observaciones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paciente  hemorragia  isquemia  fractura  masa  edema observaciones\n",
       "0          1         1.0       0.0       0.0   0.0    0.0           NaN\n",
       "1          2         1.0       0.0       1.0   0.0    1.0           NaN\n",
       "2          3         1.0       0.0       1.0   0.0    0.0           NaN\n",
       "3          4         0.0       1.0       0.0   0.0    0.0           NaN\n",
       "4          5         0.0       0.0       0.0   1.0    1.0           NaN\n",
       "5          6         1.0       0.0       0.0   0.0    0.0           NaN\n",
       "6          7         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "7          8         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "8          9         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "9         10         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "10        11         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "11        12         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "14        15         1.0       0.0       1.0   0.0    0.0           NaN\n",
       "16        17         1.0       0.0       1.0   0.0    1.0           NaN\n",
       "17        18         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "19        20         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "20        21         1.0       0.0       0.0   0.0    0.0           NaN\n",
       "21        22         1.0       0.0       1.0   0.0    1.0           NaN\n",
       "22        23         0.0       0.0       0.0   0.0    0.0           NaN\n",
       "23        24         0.0       0.0       0.0   0.0    0.0           NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosticos.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos y arquitecturas\n",
    "### Arquitecturas experimental  DNC\n",
    "* Alimentamos al modelo imagen por imagen y se presenta un solo diagnostico por paciente\n",
    "* El controller de la DNC esta compuesto por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROLLER_OUTPUT_SIZE = 128\n",
    "READ_HEADS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "class ConvController(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,4,kernel_size=3,stride=1)\n",
    "        self.fc1  =  torch.nn.Linear(262144,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        h = self.conv1(x)\n",
    "        \n",
    "        #flatten\n",
    "        h =  x.view(-1,x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        h =  self.fc1(h)\n",
    "        \n",
    "        return h #h_t in my txt\n",
    "    \n",
    "class Controller(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_controller = ConvController()\n",
    "        self.fc1 = torch.nn.Linear(10,CONTROLLER_OUTPUT_SIZE)\n",
    "        self.fc2 = torch.nn.Linear(2*CONTROLLER_OUTPUT_SIZE,CONTROLLER_OUTPUT_SIZE)\n",
    "        \n",
    "    def forward(self,x,read_vectors):\n",
    "        h_conv = self.conv_controller(x)\n",
    "        h_read_vectors = self.fc1(read_vectors)\n",
    "        \n",
    "        h_t = torch.cat((h_conv,h_read_vectors),dim=1)\n",
    "        \n",
    "        h_t =  torch.relu( h_t)\n",
    "        h_t =  self.fc2(h_t) \n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: cambiar valores quemados por valores parametrizados y calculos dependientes\n",
    "#TODO: cordar por que en algun momento le puse bias = False a los pesos del vector de salida de la DNC\n",
    "\n",
    "\n",
    "class DNC(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,controller,memory_size = (10,10),read_heads = 1,device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.controller = controller\n",
    "        self.device = device\n",
    "        self.N = memory_size[0] # number of memory locations\n",
    "        self.W = memory_size[1] # word size of the memory \n",
    "        self.R = read_heads # number of read heads\n",
    "        self.WS = 1 #not in the paper(they use 1), but used as a parametrizable number of write heads for further experiments\n",
    "        self.interface_vector_size = (self.W*self.R) + (self.W*self.WS) + (2*self.W) + (5*self.R) + 3\n",
    "        \n",
    "        # inicialization st to random just for testing, remember to put on zeros\n",
    "        #self.memory_matrix = self.memory_matrix =  nn.Parameter(torch.zeros(size=memory_size),requires_grad= False) \n",
    "        \n",
    "        #1024 es el tamaño del vector de salida del controlador, 1 es el tamaño de salida de la dnc\n",
    "        self.output_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,1,bias=True) #W_y \n",
    "        self.interface_vector_linear = torch.nn.Linear(CONTROLLER_OUTPUT_SIZE,self.interface_vector_size,bias=True) #W_ξ\n",
    "        self.read_vectors_to_output_linear = torch.nn.Linear(self.R*self.W,1,bias = True) #W_r in my txt\n",
    "        \n",
    "        self.read_keys = torch.Tensor(size=(self.R,self.W)).requires_grad_(False) # k_r in my txt\n",
    "        self.read_strenghts = torch.Tensor(size=(self.R,1)).requires_grad_(False) #β_r\n",
    "        \n",
    "        #self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(False).to(device) #r_w\n",
    "        \n",
    "        self.write_key = torch.Tensor(size=(1,self.W)).requires_grad_(False) # k_w in my txt\n",
    "        self.write_strenght = torch.Tensor(size=(1,1)).requires_grad_(False) # β_w\n",
    "        \n",
    "        #self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) # w_w\n",
    "        \n",
    "        #self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(False) #u_t\n",
    "        \n",
    "        self.memory_matrix_ones = torch.Tensor(torch.ones(size=memory_size)).requires_grad_(True).to(device) #E on paper\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def forward(self,x,read_vectors):\n",
    "        \n",
    "        h_t = self.controller(x,read_vectors) #controller output called ht in the paper\n",
    "        \n",
    "        output_vector = self.output_vector_linear(h_t) # called Vt in the paper(υ=Wy[h1;...;hL]) v_o_t in my txt\n",
    "        interface_vector = self.interface_vector_linear(h_t).data #called ξt(ksi) in the paper ,ξ_t in my txt\n",
    "        \n",
    "        self.read_keys.data = interface_vector[0,0:self.R*self.W].view((self.R,self.W)) #k_r in my txt\n",
    "        \n",
    "        #clamp temporary added because the exp was returning inf  values\n",
    "        read_strenghts =  torch.clamp( interface_vector[0,self.R*self.W:self.R*self.W+self.R].view((self.R,1)),max=85)\n",
    "        self.read_strenghts.data = self.oneplus(read_strenghts) #β_r\n",
    "        \n",
    "        self.write_key.data = interface_vector[0,self.R*self.W+self.R:self.R*self.W+self.R+self.W].view((1,self.W)) # k_w\n",
    "        \n",
    "        write_strenght = torch.clamp(interface_vector[:,self.R*self.W+self.R+self.W:self.R*self.W+self.R+self.W + 1].view((1,1)),max=85)\n",
    "        self.write_strenght.data = self.oneplus(write_strenght) #β_w\n",
    "        \n",
    "        erase_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1: self.R*self.W+self.R+self.W + 1 + self.W].view((1,self.W))\n",
    "        erase_vector = torch.sigmoid(erase_vector) #e_t\n",
    "        \n",
    "        write_vector = interface_vector[0,self.R*self.W+self.R+self.W + 1 + self.W:self.R*self.W+self.R+self.W + 1 + 2*self.W].view((1,self.W)) #v_t\n",
    "        \n",
    "        free_gates  =  interface_vector[0,self.R*self.W+self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W].view((self.R,1)) #f_t\n",
    "        free_gates =   torch.sigmoid(free_gates)\n",
    "        \n",
    "        allocation_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1]\n",
    "        allocation_gate = torch.sigmoid(allocation_gate)\n",
    "        \n",
    "        write_gate = interface_vector[0,self.R*self.W+2*self.R+self.W + 1 + 2*self.W+1:self.R*self.W+2*self.R+self.W + 1 + 2*self.W+2]\n",
    "        write_gate = torch.sigmoid( write_gate)\n",
    "        \n",
    "        \n",
    "        # Escritura\n",
    "        # TODO: verificar y/o experimentar si el ordern es :primero escribir y luego leer de la memoria(asi parece en el pazper)\n",
    "        retention_vector = (1.0 - free_gates * self.read_weighting).prod(dim=0)\n",
    "        self.usage_vector.data = (self.usage_vector +self.write_weighting - (self.usage_vector *self.write_weighting))*retention_vector #u_t\n",
    "        allocation_weighting = self.calc_allocation_weighting(self.usage_vector)\n",
    "        write_content_weighting = self.content_lookup(self.memory_matrix,self.write_key,self.write_strenght)\n",
    "\n",
    "        self.write_weighting.data =  write_gate*(  \n",
    "            (allocation_gate * allocation_weighting) +  ((1- allocation_gate)*write_content_weighting))\n",
    "        \n",
    "        new_memory_matrix = self.memory_matrix*(self.memory_matrix_ones - torch.matmul(self.write_weighting.t(),erase_vector)) + torch.matmul(self.write_weighting.t(),write_vector)\n",
    "        \n",
    "        self.memory_matrix.data = new_memory_matrix\n",
    "        \n",
    "        # read by content weithing(attention by similarity)\n",
    "        read_content_weighting = self.content_lookup(self.memory_matrix,self.read_keys,self.read_strenghts)\n",
    "        \n",
    "        #read weithing is a combination of reading modes,TODO:add temporal attention not just by similarity\n",
    "        self.read_weighting.data = read_content_weighting\n",
    "        \n",
    "        read_vectors = torch.matmul(self.read_weighting,self.memory_matrix).view((1,self.R*self.W)) #r in my txt\n",
    "        read_heads_to_output = self.read_vectors_to_output_linear(read_vectors) #v_r_t in my t xt\n",
    "        \n",
    "        #TODO: experiment and decide if maintain sigmoid\n",
    "        y_t = torch.sigmoid(output_vector + read_heads_to_output)\n",
    "        return y_t,read_vectors\n",
    "    \n",
    "    def oneplus(self,x):\n",
    "        # apply oneplus operation to a tensor to constrain it's elements to [1,inf)\n",
    "        #TODO: check numerical statiliby as exp is returning inf for numbers like 710,emporary added clamp to 85\n",
    "        return torch.log(1+torch.exp(x)) + 1\n",
    "    \n",
    "    def content_lookup(self,matrix,keys,strengths):\n",
    "        # returns a probability distribution over the memory locations \n",
    "        # with higher probability to memory locations with bigger similarity to the keys\n",
    "        # bigger strenght make more aggresive distributions ,for example a distribution (0.2,0.3,0.5) with\n",
    "        # bigger strenght becomes (0.1,0.12,0.78)\n",
    "        # returns tensor of shape (read keys,memory size) = (R,N)\n",
    "        keys_norm =  torch.sqrt(torch.sum(keys**2,dim=1).unsqueeze(dim=1))\n",
    "        matrix_norm = torch.sqrt(torch.sum(matrix**2,dim=1))\n",
    "        norms_multiplication = keys_norm*matrix_norm\n",
    "        # calc cosine similarity between keys and memory locations(1e-6 is used avoiding div by 0)\n",
    "        divide_zero_prevent_factor = torch.zeros_like(norms_multiplication).add_(1e-6)\n",
    "        cosine_similarity = torch.matmul(keys,matrix.t())/(torch.max(norms_multiplication,divide_zero_prevent_factor))\n",
    "        \n",
    "        # do a \"strenght\" softmax to calculate the probability distribution\n",
    "        numerator = torch.exp(cosine_similarity*strengths)\n",
    "        denominator = numerator.sum(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        distribution = numerator/denominator\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def calc_allocation_weighting(self,usage_vector):\n",
    "        #print(\"usage vector\",usage_vector)\n",
    "        _,free_list = torch.topk(-usage_vector,self.N,dim=1) #φt indices of memory locations ordered by usage\n",
    "        #print(\"free list\",free_list)\n",
    "        free_list = free_list.view(-1)\n",
    "        #print(\"reshaped free list\",free_list)\n",
    "        _,ordered_free_list =  torch.topk(-free_list,self.N)\n",
    "        ordered_free_list = ordered_free_list.view(-1)\n",
    "        #print(\"ordered free list\",ordered_free_list)\n",
    "        ordered_usage_vector = usage_vector[:,free_list]\n",
    "        #print(\"ordered usage vector\",ordered_usage_vector)\n",
    "        ordered_usage_vector_cumulative_product = torch.ones(size=(1,self.N+1)).to(device)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        #print(\"cumprod \",ordered_usage_vector.cumprod(dim=1))\n",
    "        ordered_usage_vector_cumulative_product[0,1:] = ordered_usage_vector.cumprod(dim=1)\n",
    "        #print(ordered_usage_vector_cumulative_product)\n",
    "        \n",
    "        allocation_weighting = (1 - usage_vector)*ordered_usage_vector_cumulative_product[0,ordered_free_list]\n",
    "        \n",
    "        return  allocation_weighting\n",
    "    \n",
    "    def reset(self):\n",
    "        self.memory_matrix =  torch.Tensor(torch.zeros(size=(self.N,self.W))).requires_grad_(True).to(device) \n",
    "        self.read_weighting = torch.Tensor(torch.zeros(size=(self.R,self.N))).requires_grad_(True).to(device) #r_w\n",
    "        self.write_weighting = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(True).to(device) # w_w\n",
    "        self.usage_vector = torch.Tensor(torch.zeros(size=(1,self.N))).requires_grad_(True).to(device) #u_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos\n",
    "* Experimentando con DNC alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_controller = Controller()\n",
    "dnc_model = DNC(controller=conv_controller,memory_size = (5,5),read_heads=2,device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_criterion = torch.nn.BCELoss()\n",
    "def loss_function(y,y_hat,last_flag):\n",
    "    #print(y,y_hat,last_flag)\n",
    "    #base_criterion = torch.nn.BCELoss()\n",
    "    return torch.full_like(y,last_flag) * base_criterion(y,y_hat)\n",
    "    #return base_criterion(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_function\n",
    "optimizer = optim.Adam(dnc_model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "source": [
    "\n",
    "total_accuracies  = []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_predictions = []\n",
    "    epoch_real_values = []\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 99999999:\n",
    "            break\n",
    "            \n",
    "        dnc_model.reset()\n",
    "        read_vectors = torch.zeros(size=(1,dnc_model.R*dnc_model.W)).to(device)\n",
    "        \n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        losses = []\n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente = imagenes_paciente[indice]\n",
    "            \n",
    "            if imagen_paciente.shape != (512,512):\n",
    "                #TODO: tread different image sizes with reshaping, resizing(or other ideas)\n",
    "                continue\n",
    "                \n",
    "            tensor_imagen_paciente =  torch.unsqueeze(\n",
    "                torch.unsqueeze( torch.Tensor(imagen_paciente),dim=0),dim=1).to(device)\n",
    "            \n",
    "            #print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_hemorragia_aproximado,read_vectors = dnc_model(tensor_imagen_paciente,read_vectors)\n",
    "            loss = criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente,last_image)\n",
    "            \n",
    "            losses.append(loss.view((1,1)))\n",
    "            \n",
    "            if last_image:\n",
    "                y_hat = diagnostico_hemorragia_aproximado.data.cpu().numpy()[0][0]\n",
    "                y_hat_hard = float(y_hat >= 0.5)\n",
    "                epoch_predictions.append(y_hat_hard)\n",
    "                epoch_real_values.append(float(diagnostico_hemorragia_paciente))\n",
    "                \n",
    "                #print(\"--Flag ultima imagen:{} diagnostico:{} valor real{}\".format(last_image,y_hat,diagnostico_hemorragia_paciente))\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                patient_loss = torch.cat(losses).sum()\n",
    "                \n",
    "                patient_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                \n",
    "        conteo_pacientes += 1\n",
    "            \n",
    "    epoch_predictions = np.array(epoch_predictions)\n",
    "    epoch_real_values = np.array(epoch_real_values)\n",
    "    correct_predictions = epoch_predictions == epoch_real_values\n",
    "    accuracy = np.average(correct_predictions)\n",
    "    total_accuracies.append(accuracy)\n",
    "    print(\"Epoch {}: accuracy {}\".format(epoch,accuracy),epoch_predictions,epoch_real_values)\n",
    "\n",
    "print(np.average(total_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controller.conv_controller.conv1.weight\n",
      "controller.conv_controller.conv1.bias\n",
      "controller.conv_controller.fc1.weight\n",
      "controller.conv_controller.fc1.bias\n",
      "controller.fc1.weight\n",
      "controller.fc1.bias\n",
      "controller.fc2.weight\n",
      "controller.fc2.bias\n",
      "output_vector_linear.weight\n",
      "output_vector_linear.bias\n",
      "interface_vector_linear.weight\n",
      "interface_vector_linear.bias\n",
      "read_vectors_to_output_linear.weight\n",
      "read_vectors_to_output_linear.bias\n"
     ]
    }
   ],
   "source": [
    "#TODO: averiguar por que salen 6 tensores de parametros si solo se han declarado 3(al momento de correr lap rueba)\n",
    "train_parmams = list(dnc_model.named_parameters())\n",
    "\n",
    "for train_param in train_parmams:\n",
    "    print(train_param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnc_model.memory_matrix.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta (por detallar))\n",
    "* L temporal link matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM con conv\n",
    "* Experimentando con lstm alimentando una imagen a la vez en orden aleatorio con pacientes también en orden aleatorio\n",
    "\n",
    "El vector de entrada de la lstm es un vector producido por una convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVNET_OUTPUT_SIZE = 1024\n",
    "CONVNET_HIDDEN_SIZE = 1024\n",
    "\n",
    "LSTM_HIDDEN_SIZE = 1024\n",
    "\n",
    "FINAL_LAYER_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda2/envs/pytorch_challenge/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "architecture = 'densenet121'\n",
    "architecture_constructor = getattr(models,architecture)\n",
    "model  =  architecture_constructor(pretrained=True)\n",
    "features_size = list(model.children())[-1].in_features\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#freeze parameters so we don't backpropagete  through them\n",
    "layers_to_freeze = 0\n",
    "layer_num = 0\n",
    "for parameter in model.parameters():\n",
    "    if layer_num >= layers_to_freeze:\n",
    "        break\n",
    "    parameter.requires_grad = False\n",
    "        \n",
    "    layer_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier = torch.nn.Sequential(OrderedDict([\n",
    "    (\"fc1\",torch.nn.Linear(features_size,CONVNET_OUTPUT_SIZE)),\n",
    "    #(\"relu\",torch.nn.ReLU()),\n",
    "    #(\"fc2\",torch.nn.Linear(CONVNET_HIDDEN_SIZE,CONVNET_HIDDEN_SIZE)),\n",
    "    #(\"relu2\",torch.nn.ReLU()),\n",
    "    #(\"fc3\",torch.nn.Linear(CONVNET_HIDDEN_SIZE,CONVNET_OUTPUT_SIZE))\n",
    "]))\n",
    "\n",
    "model.classifier = model_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,conv_net,lstm_layers=1):\n",
    "        super().__init__()\n",
    "        self.conv_net = conv_net\n",
    "        self.lstm = nn.LSTM(input_size= CONVNET_OUTPUT_SIZE,hidden_size = LSTM_HIDDEN_SIZE,num_layers=lstm_layers,batch_first = True)\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.lstm_hidden_size = LSTM_HIDDEN_SIZE\n",
    "        \n",
    "        self.output_linear = nn.Linear(LSTM_HIDDEN_SIZE,5)\n",
    "    \n",
    "    def forward(self,x,hidden):\n",
    "        x = self.conv_net(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        x,hidden = self.lstm(x,hidden)\n",
    "        x = x.contiguous().view(-1,self.lstm_hidden_size)\n",
    "        \n",
    "        x = self.output_linear(x)\n",
    "        #x = torch.sigmoid(self.output_linear(x))\n",
    "        \n",
    "        return x,hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        weigths =  next(self.lstm.parameters())\n",
    "        \n",
    "        \n",
    "        hidden = ( \n",
    "            weigths.new(self.lstm_layers,1,LSTM_HIDDEN_SIZE).zero_().to(device)\n",
    "        ,   weigths.new(self.lstm_layers,1,LSTM_HIDDEN_SIZE).zero_().to(device)\n",
    "                 )\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya que estamos usando densenet121 transformamos los datos de entrada para que tengan el tamaño adecuado\n",
    "# y se normalicen usando los valores de media y desviación estandar del dataset usado en densenet\n",
    "train_data_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lstm = ConvLSTM(model,lstm_layers=3)\n",
    "conv_lstm.to(device)\n",
    "\n",
    "base_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred,y_real):\n",
    "    \"for calculating the accurracy of multiple columns\"\n",
    "    assert y_pred.shape[1] == y_real.shape[1]\n",
    "    \n",
    "    num_columns = y_pred.shape[1]\n",
    "    \n",
    "    accuracies = []\n",
    "    for i in range(num_columns):\n",
    "        \n",
    "        colum_acc = accuracy_score(y_pred[:,i],y_real[:,i])\n",
    "        accuracies.append(colum_acc)\n",
    "        \n",
    "    return accuracies, np.mean(np.array(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: individual accs:[[0.9850746268656716, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9201492537313433 loss:0.5700129270553589\n",
      "Epoch 1: individual accs:[[0.9477611940298507, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.912686567164179 loss:0.5701905488967896\n",
      "Epoch 2: individual accs:[[0.9776119402985075, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9186567164179105 loss:0.5697008967399597\n",
      "Epoch 3: individual accs:[[0.9813432835820896, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9194029850746268 loss:0.5694061517715454\n",
      "Epoch 4: individual accs:[[0.9776119402985075, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9186567164179105 loss:0.5697637796401978\n",
      "Epoch 5: individual accs:[[0.9701492537313433, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9171641791044776 loss:0.5698954463005066\n",
      "Epoch 6: individual accs:[[0.9925373134328358, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9216417910447762 loss:0.5695045590400696\n",
      "Epoch 7: individual accs:[[0.9776119402985075, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9186567164179105 loss:0.5696560144424438\n",
      "Epoch 8: individual accs:[[0.9776119402985075, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9186567164179105 loss:0.569527268409729\n",
      "Epoch 9: individual accs:[[0.9850746268656716, 0.8917910447761194, 0.8880597014925373, 0.9738805970149254, 0.8619402985074627]] avg accuracy 0.9201492537313433 loss:0.5692936778068542\n",
      "[0.5700129, 0.57019055, 0.5697009, 0.56940615, 0.5697638, 0.56989545, 0.56950456, 0.569656, 0.56952727, 0.5692937]\n",
      "[0.9201492537313433, 0.912686567164179, 0.9186567164179105, 0.9194029850746268, 0.9186567164179105, 0.9171641791044776, 0.9216417910447762, 0.9186567164179105, 0.9186567164179105, 0.9201492537313433]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_accuracies  = []\n",
    "total_losses = []\n",
    "\n",
    "conv_lstm.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    \n",
    "    epoch_predictions = []\n",
    "    epoch_real_values = []\n",
    "    epoch_losses = []\n",
    "    # en cada epoch procesar los pacientes en orden aleatorio\n",
    "    pacientes = np.random.choice(np.array(diagnosticos.paciente),size= len(diagnosticos.paciente),replace=False)\n",
    "    \n",
    "    conteo_pacientes = 0\n",
    "    for paciente in pacientes:\n",
    "        #TODO: remover esta validacion, solo puesta para probar una unica iteracion en compu lenta\n",
    "        if conteo_pacientes >= 99999999:\n",
    "            break\n",
    "            \n",
    "        #TODO: this patient has many images and creates an out of memory error\n",
    "        if  len(diccionario_imagenes_pacientes.get(paciente)) >= 50:\n",
    "            continue\n",
    "            \n",
    "        h = conv_lstm.init_hidden()\n",
    "        \n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        conv_lstm.zero_grad()\n",
    "        \n",
    "        imagenes_paciente = diccionario_imagenes_pacientes.get(paciente)\n",
    "        diagnostico_hemorragia_paciente = np.array(float(diagnosticos[diagnosticos.paciente==paciente].hemorragia))\n",
    "        vector_diagnostico_paciente = np.array(diagnosticos[diagnosticos.paciente==paciente][[\"hemorragia\",\"isquemia\",\"fractura\",\"masa\",\"edema\"]])\n",
    "        tensor_diagnostico_paciente = torch.Tensor(vector_diagnostico_paciente).view((1,5)).to(device)\n",
    "        \n",
    "        tensor_diagnostico_hemorragia_paciente = torch.Tensor(diagnostico_hemorragia_paciente).view((1,1)).to(device)\n",
    "        \n",
    "        indices_imagenes_pacientes = np.arange(0,len(imagenes_paciente)-1,step=1)\n",
    "        indices_aleatorios_imagenes = np.random.choice(indices_imagenes_pacientes,len(indices_imagenes_pacientes),replace=False)\n",
    "        \n",
    "        losses = []\n",
    "        for indice in indices_aleatorios_imagenes:\n",
    "            #h = tuple([each.data for each in h])\n",
    "            #print(paciente,indice)\n",
    "            last_image =  int(indice  == indices_aleatorios_imagenes[-1])\n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            imagen_paciente =  np.expand_dims(imagenes_paciente[indice],2)\n",
    "            imagen_paciente =  np.repeat(imagen_paciente,3,axis=2)\n",
    "               \n",
    "            tensor_imagen_paciente =  train_data_transforms(imagen_paciente).unsqueeze(0).to(device)\n",
    "            \n",
    "            \n",
    "            #print(\"Alimentando paciente {} e imagen {} al modelo\".format(paciente,indice),imagen_paciente.shape)\n",
    "            \n",
    "            diagnostico_aproximado,h  = conv_lstm(tensor_imagen_paciente,h)\n",
    "            prob_diagnostico_aproximado = torch.sigmoid(diagnostico_aproximado)\n",
    "            diagnostico_hemorragia_aproximado = diagnostico_aproximado[:,0]\n",
    "            \n",
    "            \n",
    "            #loss = base_criterion(diagnostico_hemorragia_aproximado,tensor_diagnostico_hemorragia_paciente)\n",
    "            \n",
    "            #losses.append(loss.view((1,1)))\n",
    "            \n",
    "            if last_image:\n",
    "                \n",
    "                loss =  base_criterion(diagnostico_aproximado,tensor_diagnostico_paciente)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(conv_lstm.lstm.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                vector_y_hat_hard = prob_diagnostico_aproximado >= 0.5\n",
    "                \n",
    "                #print(torch.sigmoid(diagnostico_aproximado).data,tensor_diagnostico_paciente.data)\n",
    "                y_hat = diagnostico_hemorragia_aproximado.data.cpu().numpy()[0]\n",
    "                y_hat_hard = float(y_hat >= 0.5)\n",
    "                \n",
    "                epoch_predictions.append(vector_y_hat_hard.data.cpu().numpy()[0])\n",
    "                epoch_real_values.append(vector_diagnostico_paciente[0])\n",
    "                \n",
    "                \n",
    "                #print(\"--Flag ultima imagen:{} diagnostico:{} valor real{}\".format(last_image,y_hat,diagnostico_hemorragia_paciente))\n",
    "                #optimizer.zero_grad()\n",
    "                \n",
    "                #patient_loss = torch.cat(losses).mean()\n",
    "                \n",
    "                \n",
    "                #patient_loss.backward()\n",
    "                #loss.backward()\n",
    "                #nn.utils.clip_grad_norm_(conv_lstm.lstm.parameters(), 5.0)\n",
    "                #optimizer.step()\n",
    "                \n",
    "                epoch_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "                \n",
    "        conteo_pacientes += 1\n",
    "        \n",
    "            \n",
    "    #epoch_predictions = np.array(epoch_predictions)\n",
    "    #epoch_real_values = np.array(epoch_real_values)\n",
    "    #correct_predictions = epoch_predictions == epoch_real_values\n",
    "    #accuracy = np.average(correct_predictions)\n",
    "    accuracies,average_accuracy = calc_accuracy(np.array(epoch_predictions),np.array(epoch_real_values))\n",
    "    \n",
    "    epoch_avg_loss = np.average(epoch_losses)\n",
    "    total_losses.append(epoch_avg_loss)\n",
    "    \n",
    "    total_accuracies.append(average_accuracy)\n",
    "    print(\"Epoch {}: individual accs:[{}] avg accuracy {} loss:{}\".format(epoch,accuracies,average_accuracy,epoch_avg_loss))\n",
    "\n",
    "#print(np.average(total_accuracies))\n",
    "print(total_losses)\n",
    "print(total_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd8FHX+x/HXZ1MJJbQUSCF0SOiEKHB4UoztDlBQgqcCp+fZTk/Pdl73ziv2+514KhbwDgVFBbFRhBOlJnRIKKGFUEIoIUBI//7+2IkGCMkCuzubzef5eOQBmZ3Z+exC8t6Z+cz3K8YYlFJKqfNx2F2AUkop36ZBoZRSqlYaFEoppWqlQaGUUqpWGhRKKaVqpUGhlFKqVhoUSimlaqVBoZRSqlYaFEoppWoVaHcB7tC6dWuTkJBgdxlKKVWvrF69+rAxJqKu9fwiKBISEsjIyLC7DKWUqldEZI8r6+mpJ6WUUrXSoFBKKVUrDQqllFK1cikoROQaEdkqItki8kQNj08UkXwRWWd93WktH1pt2ToRKRaR0dZj7UVkpYhsF5GZIhJsLX9YRDJFZIOIfCUi7dz5gpVSSl2YOoNCRAKAycC1QCIwXkQSa1h1pjGmj/X1BoAxZnHVMmAYUATMt9b/B/CiMaYzcAy4w1q+Fkg2xvQCZgHPXPzLU0opdalcOaJIAbKNMTuNMaXADGDURexrLPCFMaZIRARncMyyHpsGjIbvwqXIWr4CiL2IfSmllHITV4IiBthb7ftca9nZxlini2aJSFwNj6cB71l/bwUUGGPK63jOO4AvaipKRO4SkQwRycjPz3fhZSillLoYrgSF1LDs7PlT5wIJ1umihTiPEL5/ApE2QE9gnqvPKSK3AsnAszUVZYx53RiTbIxJjoio834Rn7b3aBELM/PsLkMppWrkSlDkAtWPEGKB/dVXMMYcMcaUWN9OAfqf9Rw3Ax8bY8qs7w8DzUWk6oa/M55TREYAvwFGVntev5RXWMy415Zz5zsZHDh+2u5ylFLqHK4ERTrQ2epSCsZ5CumT6itYRwxVRgJZZz3HeL4/7YQxxgCLcV63AJgAzLGeqy/wGs6QOOT6S6l/TpWUc8e0dI6cKgXQowqllE+qMyis6wj34zxtlAW8b4zZLCJPichIa7UHRGSziKwHHgAmVm0vIgk4j0i+PuupHwceFpFsnNcs3rSWPws0AT6wWmo/wQ9VVBoenLGWzP2FvHprfzq0bsy8zRoUSinf49JYT8aYz4HPz1r2+2p//zXw6/Nsu5saLlQbY3bi7Kg6e/kIV2qqz4wxPDV3MwuzDvHnUUkM7RbJil1HePObXRwvKiM8LMjuEpVS6jt6Z7YN3lq6m2nL93DnD9pz28AEAK5Oiqa80rB4q1+fbVNK1UMaFF42b/NB/vJZJlcnRfHkdd2/W94ntjkRTUOYn3nQxuqUUupcGhRetH5vAQ/OWEuv2Oa8NK4vDsf3XcIOh3BVYhT/25pPcVmFjVUqpdSZNCi8ZO/RIu6YlkHrJiG8cXsyjYIDzlknNTGKotIKlmYftqFCpZSqmQaFFxw/XcZPp6ZTWl7B1EkDiGgaUuN6gzq2pmlIIPO1+0kp5UM0KDystLySe6evZveRU7x6W386RTY977rBgQ6u7BbJwqw8KirPvvldKaXsoUHhQcYYfvPxRpZmH+FvN/ZiUMfWdW6TmhjFkVOlrMk55oUKlVKqbhoUHvTyomw+WJ3LA8M7M7a/a4PgXtk1guAAB/M2afeTUso3aFB4yJx1+3h+wTZu6BvDQyM6u7xd09AgBnVqxfzMPJwjnSillL00KDxg1a6jPPrBBi5r35K/j+mJc/oN16UmRpNztIiteSc8VKFSSrlOg8LNduaf5K7/ZBDbshGv35ZMSOC5bbB1GZEYiQja/aSU8gkaFG505GQJk6amEyDC1IkpFz1mU2TTUPrGNde7tJVSPkGDwk2Kyyr42TsZHDxezJQJycS3Cruk50tNimbTvkJyjxXVvbJSSnmQBoUbVFYafvX+etbkFPDiuD70i29xyc95dVI0AAt0jgqllM00KNzgmXlb+WzjAX59bTeu69mm7g1c0L51YzpHNtHrFEop22lQXKL3VuXw6tc7uOWyeO66ooNbnzs1KYpVu49yzJoBTyml7KBBcQm+3pbPb2dv4oddInhqZNIFt8HWJTUxmopKw1dbdI4KpZR9NCguUtaBQu6bvoYuUU2Z/JN+BAa4/63sFRtOdLNQ5m/W7iellH00KC5CXmExP52aTuOQAN6amEyTEJdmlL1gIkJqUhRLtudzulTnqFBK2UOD4gKdKinnp1PTKTxdxlsTB9AmvJFH95eaGE1xWSXfbM/36H6UUup8NCguQHlFJb94by1ZBwp5+ZZ+JLUN9/g+L+vQkmahgczXNlmllE00KFxkjOGpTzNZtOUQfxrVg6HdIr2y36AAB8O7R/FVVh7lFZVe2adSSlWnQeGiN7/dxTvL9/CzIe257fJ2Xt13amIUx4rKSN+tc1QopbxPg8IFX246yNOfZ3Ftj2h+fW13r+//ii4RBAc6dOwnpZQtNCjqsG5vAb+cuZbesc15cVwfHA733ivhisYhgQzp1Jr5m3WOCqWU92lQ1GLv0SLunJZORNMQ3piQTGjQhQ8Z7i6pSVHsKzhN5oFC22pQSjVMGhTncfx0GZOmplNaXsnbEwfQukmIrfWM6B6FQ2Cejv2klPIyDYoalJZXcvd/VrPnyCleuy2ZTpFN7S6JVk1CSG7XUu/SVkp5nQbFWYwx/PqjjSzfeYS/39iLgR1b2V3Sd1KTothy8AQ5R3SOCqWU92hQnOVfi7L5cE0uDw7vzJj+sXaXc4bUROccFdr9pJTyJg2Kamav3ccLC7ZxY98Yfjmis93lnCO+VRjdopvqHBVKKa/SoLCs3HmEx2Zt4PIOLfn7mF5uHzLcXVKTosnYc5TDJ0vsLkUp1UBoUAA78k9y139WE9eyEa/dmkxwoO++LamJUVQaWJSlc1QopbzDd38jesmRkyVMejudQIfw9sQUwsOC7C6pVkltmxHTvJFep1BKeU2DDorisgrufCeDvMJi3piQTHyrMLtLqpOIcFViFEu2H+ZUSbnd5SilGgCXgkJErhGRrSKSLSJP1PD4RBHJF5F11ted1vKh1ZatE5FiERltPdZeRFaKyHYRmSkiwdbyEOv7bOvxBPe93DPNWbePdXsLeGlcH/rGt/DUbtzu6qRoSssrWbJN56hQSnlenUEhIgHAZOBaIBEYLyKJNaw60xjTx/p6A8AYs7hqGTAMKALmW+v/A3jRGNMZOAbcYS2/AzhmjOkEvGit5xE3J8cx+97BXNuzjad24REDElrQPCxI56hQSnmFK0cUKUC2MWanMaYUmAGMuoh9jQW+MMYUibOlaBgwy3psGjDa+vso63usx4eLh1qQRITecc098dQeFRjgYHg35xwVZTpHhVLKw1wJihhgb7Xvc61lZxsjIhtEZJaIxNXweBrwnvX3VkCBMabqJHv15/xuf9bjx631zyAid4lIhohk5Oc3vFMwqUlRFBaXs2rXUbtLUUr5OVeCoqZP82ePdT0XSDDG9AIW8v0RgfMJRNoAPYF5LjynK/vDGPO6MSbZGJMcERFRS/n+6YrOEYQGOZinYz8ppTzMlaDIBaofIcQC+6uvYIw5YoypugNsCtD/rOe4GfjYGFNmfX8YaC4igTU853f7sx4PB/Rj81kaBQdwRecInaNCKeVxrgRFOtDZ6lIKxnkK6ZPqK1hHDFVGAllnPcd4vj/thHH+ZluM87oFwARgjvX3T6zvsR5fZPQ3YY1Sk6I5WFjMxn3H7S5FKeXH6gwK6zrB/ThPG2UB7xtjNovIUyIy0lrtARHZLCLrgQeAiVXbW+2tccDXZz3148DDIpKN8xrEm9byN4FW1vKHgXPacZXT8G6RBDhEx35SSnmU+MOH9eTkZJORkWF3GbYY//oKjpwqYf5DP7S7FKVUPSMiq40xyXWt16DvzPYHqUlRbMs7ya7Dp+wuRSnlpzQo6rmrEqMAdOY7pZTHaFDUc7Etwkhq20zv0lZKeYwGhR9ITYxmTc4xDp0otrsUpZQf0qDwA1f3iMIYWJipc1QopdxPg8IPdI1qSnzLMJ2jQinlERoUfkBESE2MYln2EU4Ul9W9gVJKXQANCj+RmhRNaUUlX+scFUopN9Og8BP927WgVeNgvUtbKeV2GhR+IsAhjOgexeIthygt1zkqlFLuo0HhR1KTojhRUs7ynUfsLkUp5Uc0KPzI4E6tCQsO0Lu0lVJupUHhR0KDAriyawQLMvOorKz/gz0qpXyDBoWfSU2M5tCJEtbnFthdilLKT2hQ+JmhXSMJdAjztPtJKeUmGhR+JjwsiMs7tNK7tJVSbqNB4YdSk6LYmX+K7EMn7S5FXaKi0nLmrNtHWYW2PCv7aFD4oe/mqNCjinotr7CYm19bzoMz1vFBRq7d5agGTIPCD7UJb0Tv2HC9TlGPZR0oZPTkpezMP0Wb8FBmpufYXZJqwDQo/FRqUjTr9xZw8LjOUVHfLN56iLH/XkalMXxw90B+NqQD63OPk7m/0O7SVAOlQeGnUq3TTwuy9KiiPvnPij3cMTWddq0aM/u+wSS1DefGfjEEBzr0qELZRoPCT3WKbEKH1o31Lu16oqLS8JdPM/nd7E1c2TWSD+4eSJvwRgA0DwvmmqRoPl67j+KyCpsrVQ2RBoWfEhGuSopi+Y4jHD+tc1T4sqLScu7+72re+HYXEwclMOX2ZBqHBJ6xTlpKHIXF5Xyx6YBNVaqGTIPCj6UmRlNeafjfVp0i1VcdKixm3Gsr+Corjz/8OJE/jkwiwCHnrHd5+1a0axXGe6v22lClaug0KPxY37jmtG4SonNU+KgtB52dTTvyT/L6bclMGtz+vOs6HMK4AXGs2nWUnfl6f4zyLg0KP+ZwCFclRvG/rYf03LaP+XpbPmP/vZwKY3j/5wMZYTUf1GZsv1gCHMLMdD2qUN6lQeHnrk6K4lRpBct36BwVvuK/K/bw06npxLUMY/Z9g+kRE+7SdpHNQhneLZIP1+Tq5FTKqzQo/NzAjq1oEhLIPO1+sl1lpeHpzzL57exNXNG59RmdTa5KS4nj8MlSvtK2Z+VFGhR+LiTQOUfFwqw8KnSOCtucLq3gnumrmfLNLm4f2I4ptyfT5KzOJlf8sEsk0c1CmaGnn5QXaVA0AKlJ0Rw+WcranGN2l9IgHTpRTNrry5mfmcfvf5TIn0YmERhwcT96AQ7h5uRYlmzPJ/dYkZsrVapmGhQNwNCuEQQFCPMz9XSFt209eIIbJi9jW56zs+mnP2iPyLntrxfipuQ4AB0oUHmNBkUD0DQ0iEEdWzNv80GM0dNP3rJkWz5j/72MsopK3v/5wO9G9b1UcS3D+EGn1nyQsVdPJyqv0KBoIFKTothzpIhtedqD7w3vrsxh0tR0Ylo0YvZ9g+kZ61pnk6vGp8Sz/3gxS7bnu/V5laqJBkUDcVX3KETQsZ88rLLS8LfPs3jy443OT/13D6Rt8wvrbHLFiO5RtGoczIxVOlCg8jwNigYislkofeOa63UKDzpdWsF9767htSU7ufXyeN6ckEzT0CCP7Cs40MGY/rF8lXWIQyd0KHnlWS4FhYhcIyJbRSRbRJ6o4fGJIpIvIuusrzurPRYvIvNFJEtEMkUkwVo+TETWiMgmEZkmIoHW8nARmSsi60Vks4hMcs9LValJ0Wzcd5z9BaftLsXvHDpRTNqUFXy5+SC/vb47fx7V46I7m1x1c3Ic5ZWGD1fv8+h+lKrzf7KIBACTgWuBRGC8iCTWsOpMY0wf6+uNasvfAZ41xnQHUoBDIuIApgFpxpgewB5ggrX+fUCmMaY3cCXwvIgEX9zLU9VVzVGhp5/ca1ues7Np68FCXr21P3cO6XDJnU2u6BTZhJSElsxMz9EmBeVRrnzkSQGyjTE7jTGlwAxglCtPbgVKoDFmAYAx5qQxpghoBZQYY7ZZqy4Axlh/N0BTcf6kNQGOAuWuviB1fh0imtApsomefnKjb7cfZswryyi1OpuuTor26v7HDYhj95EiVuw86tX9qobFlaCIAarfBpprLTvbGBHZICKzRCTOWtYFKBCRj0RkrYg8ax2hHAaCRCTZWm8sULXNy0B3YD+wEXjQGHPOwDYicpeIZIhIRn6+dn64KjUxipW7jlJQVGp3KfXejFU5THx7FW2bOzubesU293oN1/VsQ9PQQJ39TnmUK0FR0zH02ce5c4EEY0wvYCHO00oAgcAQ4BFgANABmGicx8lpwIsisgo4wfdHDVcD64C2QB/gZRFpdk4BxrxujEk2xiRHRES48DIUwNVJ0VRUGhZt0TkqLlZlpeHvX2zhiY82MrBjK2bdM5AYD3Q2uaJRcACj+8Tw+aaDGv7KY1wJily+/7QPEIvz0/53jDFHjDEl1rdTgP7Vtl1rnbYqB2YD/axtlhtjhhhjUoAlwHZrm0nAR8YpG9gFdLvwl6Zq0jMmnOhmoTpHxUUqLqvg/vfW8OrXO7jlsnjenjjAY51NrkpLiaO0vJLZa/WitvIMV4IiHegsIu2ti8ppwCfVVxCRNtW+HQlkVdu2hYhUfeQfBmRa20Raf4YAjwOvWuvkAMOtx6KArsDOC3tZ6nyq5qj4elu+zlFxgQ6fLCHt9RV8sekgv7muO0+P9nxnkyuS2obTMyacGel79aK28og6/5dbRwL3A/NwBsD7xpjNIvKUiIy0VnvAamVdDzwATLS2rcB52ukrEdmI8zTWFGubR0UkC9gAzDXGLLKW/xkYZK3/FfC4MeawG16rsqQmRXG6rIJvtuvb6qrteScYPXkpWw4W8u+f9OdnV3ins8lVaSlxbDl4gvW5x+0uRfkh8YdPIMnJySYjI8PuMuqNsopK+v15AdckRfPsTb3tLsfnLc0+zN3/XU1IYABvTkimd5z3L1rX5URxGSlPf8WoPm35+5hedpej6gkRWW2MSa5rPfuPm5XXBQU4GN4tkoVZeZRX6ExptXk/fS8T3lpFm/BQZt83yCdDApwDP/6oVxs+Wb+fkyXaTa7cS4OigUpNiuZYURmr9+gcFefz3LytPPbhBquzaRCxLcLsLqlWaSlxFJVW8On6/XWvrNQF0KBooH7YJYLgQAfztPupRmtzjvHy4mzG9o/lrYkDaGZzZ5Mr+sW3oHNkE539TrmdBkUD1TgkkCGdWjM/U+eoqMm0ZbtpEhLIH0cmEeQDnU2uEBHGDYhj3d4CthwstLsc5Ufqx0+A8ojUpChyj50m68AJu0vxKYcKi/ls4wHG9o+9qHmt7XRjv1iCAxzMWKVHFcp9NCgasOFVc1Rk6iCB1U1fmUNZhWHCoAS7S7lgLRsHk5oUxcdr9+l9MsptNCgasNZNQkhu10KvU1RTUl7B9JU5DO0aQfvWje0u56KMT4nn+Oky5ukowcpNNCgauNTEaLIOFLL3aJHdpfiEzzce4PDJEiYObm93KRdtYIdWxLVspKeflNtoUDRwqUnWHBU69DgAU5fupkNEY4Z0am13KRfN4RDSBsSzfOcRdh8+ZXc5yg9oUDRw7Vo1plt0U53MCGdL7Prc40wclIDD4TvDc1yMsf1jCXAIMzP0qEJdOg0KRWpiFOm7j3L0VMMepnqq1RJ7Y79Yu0u5ZFHNQhnaNZIPMnIp07vv1SXSoFCkJkVTaWBhVsM9/ZRXWMxnGw5wU3L9a4k9n7QBcRw+WaJzj6hLpkGhSGrbjJjmjRr0HBXTV+ZQYQwTBibYXYrbXNk1gqhmIcxYpbPfqUujQaEQcc5R8c32fIpKG96AciXlFby7cg9Du0aSUE9bYmsSGODgpv5xfL0tn/0Fp+0uR9VjGhQKcHY/lZRXsmRbw5ujwtkSW8rEeniDXV3GDYij0sAHGbl2l6LqMQ0KBUBKQkvCGwU1uO4nYwxvL91Nx4jGDOlcf1tizyeuZRg/6NSa9zP2UlGpY3qpi6NBoQDnaYrrerbh040HOHC84ZymWLu3gA25x5kwKMGnZqxzp7SUOPYVnObb7IZ3tKjcQ4NCfefeKztijOFfi7LtLsVrpi7dTVM/aYk9n6sSo2gRFsTMdL2orS6OBoX6TlzLMManxPN++l72HPH/O3rzCov5fOMBbkqO85uW2JqEBAYwpl8sCzLzOHyyxO5yVD2kQaHOcP/QTgQGCC8t3G53KR43fcUeKozh9oHt7C7F49JS4iirMHy0Ri9qqwunQaHOENkslAmDEpi9bh/b8vx3noqS8greXZXDMD9riT2fTpFNSW7Xghnpe3WiKnXBNCjUOe6+oiNNggN5Yf42u0vxmM82WC2xgxPsLsVrxg2IY2f+KdJ36zzp6sJoUKhztGgczB1D2vPl5oNsyC2wuxy3q94S+4N6PErshbq+VxuahgTqndrqgmlQqBrd8YP2tAgL4jk/PKpYk1PAxn3OUWL9tSW2JmHBgYzs05bPNh7g+Okyu8tR9YgGhapR09Ag7rmyI0u25bNy5xG7y3Grqcv8vyX2fManxFNSXsmcdfvsLkXVIxoU6rxuH5hAZNMQnpu/1W8ugOYVFvPFxgPcPCCOxn7cEns+PWLCSWrbjPdW1c+L2p9tOMAzX26hpFznA/cmDQp1XqFBAfxiWCfSdx/j6235dpfjFg2pJfZ80lLiyTpQyMZ9x+0u5YK8n76X+99bwyv/28FPpqzkiN4T4jUaFKpW4wbEE9uiEc/P31YvP4FWV1JewfSVOQzvFkm7Vv7fEns+o/q0JTTIwYz0+jP73bsrc3jsww0M6RzB8zf1ZuO+44yavNSvW7h9iQaFqlVwoINfjujCxn3HmVfPBwz8dP0BjpwqZeKg9naXYqtmoUFc37Mtn6zbz6kS3x9W/j8r9vDkxxsZ2jWC12/rz5j+scz8+UBKyiu58ZVlLN6qEzN5mgaFqtMNfWPoGNGY5+Zvq7cjkBpjmLpsN50imzC4Uyu7y7FdWkocJ0vK+WzjAbtLqdU7y3fzu9mbGN4tkldv609oUAAAfeKaM+e+wcS3DOOOqem89e2uen/E68s0KFSdAhzCw1d1JfvQyXrbLbMm5xgb9/n3KLEXIrldCzpGNPbpeyre+nYXv5+zmasSo3jl1n6EBAac8Xjb5o344O6BjOgexVOfZvKb2Zt0fnAP0aBQLrm2RzRJbZvx0sLt9fKHceqyPTQNDeTGvjF2l+ITRIS0AfGsySnwyfP8b3yzk6c+zeTqpCgm33JuSFRpHBLIq7f25+4fduTdlTlMfHsVx4v0HhF306BQLnE4hEdSu5JztIj3M+rPRVCAg8edLbHjkhtmS+z53NgvhqAAYcYq3/r3fO3rHfzlsyyu6xnNy7f0Iziw9l9TDofwxLXdeO6m3qzadZQbXlnKrsP+P/qxN2lQKJdd2TWC/u1a8H9fbae4rP70sU9fWdUSm2B3KT6lVZMQUhOj+Whtrs/clzB5cTZ/+2ILP+rVhn+m9SUowPVfUWP7x/Luzy6n4HQZoycvZZlO1OQ2GhTKZSLOo4q8whL+u2KP3eW4pLisgndX5jC8WxTxrcLsLsfnpKXEUVBUxrzNeXaXwr++2s6z87Yyqk9bXhrX54JCosqAhJbMvncwkU1DuP2tVby70nevwdQnLv1LiMg1IrJVRLJF5IkaHp8oIvkiss76urPaY/EiMl9EskQkU0QSrOXDRGSNiGwSkWkiElhtmyut59ksIl9f+stU7jKwYyuGdG7NK//bwcl60Fr56YaqltgEu0vxSYM7tia2RSPbZ797aeE2nl+wjRv6xvDCzX0IvIiQqBLfKowP7x3E4E6tefLjjTw1N7Peduv5ijr/NUQkAJgMXAskAuNFJLGGVWcaY/pYX29UW/4O8KwxpjuQAhwSEQcwDUgzxvQA9gATrP01B14BRhpjkoCbLv7lKU/4VWpXjp4q5a1vd9ldSq2cLbG7tCW2Fg6HMC45jqXZR2yZ1dAYwwvzt/LSwu2M6RfLczf1JsBx6V1pzUKDeHNCMpMGJ/DW0l3cOS2dE8V6kftiuRLbKUC2MWanMaYUmAGMcuXJrUAJNMYsADDGnDTGFAGtgBJjTNXQpAuAMdbfbwE+MsbkWNvo3TQ+pk9cc65KjGLKkp0UFJXaXc55rck5xqZ9hQ1ulNgLNTY5Fofg9SYFYwzPzd/K/y3K5ubkWJ4d28stIVElMMDBH36cxNM39GDJ9sOM+fcy9h4tctvzNySuBEUMUP1/UK617GxjRGSDiMwSkThrWRegQEQ+EpG1IvKsdYRyGAgSkWRrvbFA9W1aiMj/RGS1iNxeU1EicpeIZIhIRn6+f4xDVJ/8KrULJ0vLeW3JTrtLOa+3l+52tsT205bY2rQJb8TQrpF8kJFLuZdan40x/OPLrUxevIPxKXH8/cZeONwYEtX95LJ2vPPTFA4eL2bU5KVk7D7qkf34M1eCoqZ/vbNP+M0FEowxvYCFOE8rAQQCQ4BHgAFAB2Cicd5CmQa8KCKrgBNAebVt+gPXA1cDvxORLucUYMzrxphkY0xyRESECy9DuVO36GaM7N2WqUt3c+hEsd3lnOPA8dN8sekgaQPiCAvWlti6jBsQx6ETJSze6vkPXcYY/vp5Fq9+vYOfXBbP06N7eiwkqgzu1JqP7xtMeKMgbpmyUucOv0CuBEUu33/aB4gF9ldfwRhzxBhTNZTjFJy/6Ku2XWudtioHZgP9rG2WG2OGGGNSgCXA9mrbfGmMOWWMOWw91vvCX5rytIdGdKG0opJXFu+wu5RzTF+RQ6W2xLpsWLdIIpuGePxObWMMf/40iynf7OL2ge34y+geHg+JKh0jmvDxvYPo364FD7+/nme+3EKlXuR2iStBkQ50FpH2IhKM80jgk+oriEibat+OBLKqbdtCRKo+8g8DMq1tIq0/Q4DHgVetdeYAQ0QkUETCgMuqPZ/yIQmtG3NT/1jeXZnDvoLTdpfzneKyCt5d5WyJjWupLbGuCAxwMLZ/LIu3HuLgcc8cIRpj+NPcTN5auouJgxL408gkr187ah4WzDt3pDA+JY5X/reDe6avpqjU97v37FZnUFhHAvcD83D+wn7fGLNZRJ4SkZHWag9YrazrgQeAida2FTgvkt08AAAR+klEQVRPO30lIhtxnsaaYm3zqIhkARuAucaYRdY2WcCX1vJVwBvGmE1uebXK7X4xvDMA/7dwex1res+nGw5w9FQpkwYn2F1KvTJuQByVBj7wwEXtykrD7+dsZuqy3dzxg/b84ceJtjUYBAU4+OsNPfndjxJZkJnHTa8u58Bx3/mg44vEH0ZcTE5ONhkZGXaX0WD9ae5m3lm+hwUPXUGHiCa21mKM4Uf/+pbS8krmP3SFdjtdoFumrCDnaBFLHh3qtlNClZWG387ZxLsrc/j5FR144tpuPvPvsmhLHg+8t46w4ACm3J5M77jmdpfkVSKy2hiTXNd6eme2umT3XtmJ4AAHL/rAUcXqPcfYvL+QiYO1JfZipKXEk3vsNEt3uGf4i8pKw5Mfb+TdlTncc2VHnwoJgGHdovjwnkEEBzq4+bXlfLbBt4ddt4sGhbpkEU1DmDQ4gbnr95N1oNDWWt5etptmoYHcoKPEXpTUxCiahwW5Zfa7ikrD4x9uYEb6Xu4f2onHru7qUyFRpWt0U2bfN5ieMeHc9+4a/u+r7Tq3xVk0KJRb/PyKjjQNDeT5+dvqXtlDDhw/zZebDpKWEq8tsRcpNCiAG/vGMn/zwUuak7qi0vDorPV8sDqXB4d35lepXXwyJKq0bhLC9J9dxo19Y3hhwTZ+OXNdvRr40tM0KJRbhIcF8fMrOrAwK4+1OcdsqeG/K/ZQaQy3Xd7Olv37i7SUOMoqDB+vvbhJqsorKvnV++v4aM0+HhrRhYeu8u2QqBISGMDzN/fm0au7MmfdftJeX+GT9wjZQYNCuc2kwe1p1TiY5+Zv9fq+i8sqeG/VXkZ015bYS9Ulqin94pszI33vBZ+CKa+o5KH31zN73X4eSe3CgyM6e6hKzxAR7hvaiVdv7cfWgycY/fJS20+n+gINCuU2jUMCuefKjizNPsIyN10MddXc9fudLbE6SqxbpA2IJ/vQSVbvcf3osKyikgdnrmPu+v08fk037h9Wv0Kiumt6tOGDuwdSaWDMv5exMNP+YdjtpEGh3OrWy9vRJjyU5+Zt9doFQecosbvpEtWEgR11lFh3uL5XG5qEBLp8UbusopIH3lvLZxsO8OR13bjnyo4ertDzesSEM+f+wXSKbMLP/pPB60t2NNiL3BoUyq1CgwL4xbDOrMkpYNEW7wz8m1HVEjuofb04F14fNA4J5Me92/Lphv0U1jE8d2l5JfdNX8MXmw7y2+u7c9cV9T8kqkQ1C2XmXQO5rkcb/vr5Fh7/cAOl5fVvzvhLpUGh3O6m5FjatQrjufnbvDKWztSluwlvFMTovm09vq+GZHxKHMVllXyybv951ykpr+De6WuYn5nHH36cyJ1DOnixQu9oFBzAv8b35YFhnXg/I5fb3lzJsVO+O7y+J2hQKLcLCnDwyxGdyTpQyOebPHsD0/6C03y5+SDjdJRYt+sZE073Ns2YcZ7Z74rLKrjnv2tYmJXHU6OSmDS4vZcr9B6HQ3g4tSv/TOvD2r0FjH5lKdmHTtpdltdoUCiPGNk7hi5RTXhhwTaPznEwfeUejLbEeoSIMD4ljk37Ctm07/gZjxWXVfDz/6xm0ZZDPH1DjwYzSu+oPjHMuOtyTpWUM2nqqgYzoKAGhfKIAIfw8FVd2Zl/io8ush+/LsVlFby7MkdbYj1oVO8YQgIdZxxVFJdV8LN3Mvh6Wz5/u7EnP7msYYV0v/gWTL6lH3uPnubZed5vBbeDBoXymKuTougVG84/F26npNz9d7l+sn4/x4rKmKijxHpMeFgQ1/dsw5y1+zldWsHp0grunJbBt9mHeWZML8anxNtdoi0u69CK2we2Y+qy3Q1ixjwNCuUxIsKvUruyr+A0M90wdlB1xhimLt1N16imDOygLbGeNG5AHCdKypm1JpefTk1n6Y7DPDu2NzcPiKt7Yz/22DXdaBveiMdmbfD74T40KJRHXdG5NSntW/KvRdmcLnXfD1P67mNkHtBRYr0hpX1LOrRuzO/nbGLlriO8cHNvxvaPtbss2zUJCeTvY3qy8/ApXvKBkZM9SYNCeZSI8OjVXck/UcK05bvd9rzTllktsX10lFhPExFuH9gOhwgvjuvDDX01JKoM6RxB2oA4Xl+yg/V7C+wux2M0KJTHDUhoyQ+7RPDq1zvqvHnLFVUtsWkD4mgUHOCGClVdJgxKYPVvRzBKg/kcT17fncimoTw2y39vxtOgUF7xSGpXCorKePObXZf8XP9d4WyJvVVbYr1GRGgeFmx3GT6pWWgQT9/Qg615J5i8ONvucjxCg0J5Rc/YcK7tEc2b3+7i6CXc1eocJTaHqxK1JVb5juHdo7ihbwyTF2eTud//RpvVoFBe8/BVXThVWs6rX++46Of4ZJ3VEjvIf+8CVvXT73+USPOwIB6dtZ4yD95kagcNCuU1naOackOfGKYt201e4YVPCGOM4e1lu+kW3ZTLO7T0QIVKXbwWjYP586gebN5fyOtLdtpdjltpUCiv+uWILlRUGl5edOHnctN3HyPrQCETB2lLrPJN1/Zsw/U92/DPhdvJPnTC7nLcRoNCeVV8qzDGDYjjvVU57D1adEHbTl22i/BGQdp5o3zaH0cm0TgkgEdnbaDCC6Mne4MGhfK6XwzrTIBDLugmpX0Fp5m3OY+0FG2JVb4tomkIfxyZxNqcAt5eeuldfr5Ag0J5XXR4KLdd3o6P1+a6fHhe1RKro8Sq+mBk77aM6B7Jc/O3svvwKbvLuWQaFMoW91zZkUZBAby4oO6jiqqW2NTEaGJbaEus8n0iwl9G9yQowMFjH27wygRenqRBoWzRqkkId/ygPZ9tPHDOXAdn+2Tdfgp0lFhVz0SHh/K76xNZteso01fusbucS6JBoWxz5xUdCG8UxPPzzz+mf/WW2Mvaa0usql9uSo5lSOfW/O2LLRfcvOFLNCiUbZqFBvHzH3Zg8dZ8Vu+peUz/VbuOakusqrdEhL/d2BMBnvx4I8bUz1NQGhTKVhMHJdC6SQjPfLm1xh+iqct20zxMW2JV/RXbIownruvON9sP80FGrt3lXBQNCmWrsOBA7h/akZW7jvJt9uEzHnO2xB4kbUC8tsSqeu0nKfFc1r4lf/4sk4PHL3xUArtpUCjbjb8snpjmjXhu3plHFf9Z7rwAeNtAbYlV9ZvDIfxjTC/KKir5TT08BaVBoWwXEhjAA8M7sT73OAsy8wBnS+yM9ByuToompnkjmytU6tIltG7MI6ld+WrLIeas2293ORdEg0L5hDH9YmnfujHPz99GZaVhzrp9zpbYQQl2l6aU20wa3J5+8c3549zN5J8osbscl2lQKJ8QGODgoau6sDXvBHM37Oftpc6W2BRtiVV+JMAhPDO2N0WlFfzhk012l+Myl4JCRK4Rka0iki0iT9Tw+EQRyReRddbXndUeixeR+SKSJSKZIpJgLR8mImtEZJOITBORwLOec4CIVIjI2Et7iaq++FHPNnSLbsrvZm9iy8ETTBqsLbHK/3SKbMIvR3Tm840H+XzjAbvLcUmdQSEiAcBk4FogERgvIok1rDrTGNPH+nqj2vJ3gGeNMd2BFOCQiDiAaUCaMaYHsAeYcNY+/wHMu8jXpeohh0N4JLUrhcXl2hKr/NpdQzrQMyac38/ZxLFLmPHRW1w5okgBso0xO40xpcAMYJQrT24FSqAxZgGAMeakMaYIaAWUGGO2WasuAMZU2/QXwIfAIddehvIXw7tHMrpPWx4a0YXQIG2JVf4pMMDBM2N7UVBUxlOfZtpdTp1cCYoYYG+173OtZWcbIyIbRGSWiMRZy7oABSLykYisFZFnraOFw0CQiCRb640F4gBEJAa4AXi1tqJE5C4RyRCRjPz8fBdehqoPRISX0voyQS9iKz/XvU0z7hvaiY/X7uOrrDy7y6mVK0FR00nis5uA5wIJxphewEKcp5UAAoEhwCPAAKADMNE4m4jTgBdFZBVwAii3tnkJeNwYU1FbUcaY140xycaY5IiICBdehlJK+Zb7hnaiW3RTnvx4I8dPl9ldznm5EhS5WJ/2LbHAGU3AxpgjxpiqXq8pQP9q2661TluVA7OBftY2y40xQ4wxKcASoGq86WRghojsxnmk8YqIjL7gV6aUUj4uONDBs2N7c/hkKX/9LMvucs7LlaBIBzqLSHsRCcZ5JPBJ9RVEpE21b0cCWdW2bSEiVR/5hwGZ1jaR1p8hwONYp5qMMe2NMQnGmARgFnCvMWb2Rbw2pZTyeT1jw7nrig7MzNjLN9t98zR6nUFhHQncj7MDKQt43xizWUSeEpGR1moPiMhmEVkPPABMtLatwHna6SsR2YjzNNYUa5tHRSQL2ADMNcYscuPrUkqpeuPB4Z3pENGYJz7cyMmS8ro38DKpb2OO1CQ5OdlkZGTYXYZSSl201XuOMvbV5dx2eTueGtXDK/sUkdXGmOS61tM7s5VSygf0b9eSSYPa887yPazYecTucs6gQaGUUj7ikau7EN8yjMc/3MDp0lobP71Kg0IppXxEWHAg/xjTiz1HimqdItjbNCiUUsqHDOzYilsvj+fNpbtYk3PM7nIADQqllPI5T1zbnbbhjXhs1gaKy+w/BaVBoZRSPqZJSCB/vbEn2YdO8q9F2+vewMM0KJRSygf9sEsEN/WP5dWvd7Jp33Fba9GgUEopH/Xb6xNp1TiYRz5YT2l5pW11aFAopZSPCg8L4ukberLl4An+/b8dttWhQaGUUj7sqsQoRvVpy8uLt7PlYKEtNWhQKKWUj/vDj5NoFhrEY7M2UF7h/VNQGhRKKeXjWjYO5qlRPdiQe5w3vt3l9f1rUCilVD1wXc9orkmK5oUF29iRf9Kr+9agUEqpekBEeGp0EmHBATw2awMVld4b+VuDQiml6onIpqH84ceJrN5zjGnLdnttvxoUSilVj4zuE8OwbpE8M28Le46c8so+NSiUUqoeERGevqEHQQ4HT3y4kUovnILSoFBKqXqmTXgjfnN9d5bvPMJ76Tke31+gx/eglFLK7cYNiGPZjiO0DAv2+L40KJRSqh4SEf5vfF+v7EtPPSmllKqVBoVSSqlaaVAopZSqlQaFUkqpWmlQKKWUqpUGhVJKqVppUCillKqVBoVSSqlaiTHeG6rWU0QkH9hzkZu3Bg67sZz6Tt+PM+n78T19L87kD+9HO2NMRF0r+UVQXAoRyTDGJNtdh6/Q9+NM+n58T9+LMzWk90NPPSmllKqVBoVSSqlaaVDA63YX4GP0/TiTvh/f0/fiTA3m/Wjw1yiUUkrVTo8olFJK1apBB4WIXCMiW0UkW0SesLseO4lInIgsFpEsEdksIg/aXZPdRCRARNaKyKd212I3EWkuIrNEZIv1f2Sg3TXZRUQesn5GNonIeyISandNntZgg0JEAoDJwLVAIjBeRBLtrcpW5cCvjDHdgcuB+xr4+wHwIJBldxE+4p/Al8aYbkBvGuj7IiIxwANAsjGmBxAApNlblec12KAAUoBsY8xOY0wpMAMYZXNNtjHGHDDGrLH+fgLnL4IYe6uyj4jEAtcDb9hdi91EpBlwBfAmgDGm1BhTYG9VtgoEGolIIBAG7Le5Ho9ryEERA+yt9n0uDfgXY3UikgD0BVbaW4mtXgIeAyrtLsQHdADygbetU3FviEhju4uygzFmH/AckAMcAI4bY+bbW5XnNeSgkBqWNfgWMBFpAnwI/NIYU2h3PXYQkR8Bh4wxq+2uxUcEAv2Afxtj+gKngAZ5TU9EWuA889AeaAs0FpFb7a3K8xpyUOQCcdW+j6UBHELWRkSCcIbEdGPMR3bXY6PBwEgR2Y3zlOQwEfmvvSXZKhfINcZUHWHOwhkcDdEIYJcxJt8YUwZ8BAyyuSaPa8hBkQ50FpH2IhKM84LUJzbXZBsREZznoLOMMS/YXY+djDG/NsbEGmMScP6/WGSM8ftPjedjjDkI7BWRrtai4UCmjSXZKQe4XETCrJ+Z4TSAC/uBdhdgF2NMuYjcD8zD2bnwljFms81l2WkwcBuwUUTWWcueNMZ8bmNNynf8AphufajaCUyyuR5bGGNWisgsYA3OTsG1NIA7tPXObKWUUrVqyKeelFJKuUCDQimlVK00KJRSStVKg0IppVStNCiUUkrVSoNCKaVUrTQolFJK1UqDQimlVK3+Hyx+/iokg/3AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "* El mejor resultado hasta ahora ha sido no congelar pesos(entranar toda la convnet densenet121) agregandole una sola capa fully connected de salida, y 3 layers en la lstm, todas las capas con 1024 de tamaño. Lr = 0.001.\n",
    "* Congelando las primeras 50 capas de la convnet converge alrededor de los 40 epochs(pero sigue bajando) con la misma configuración qeu el resultado 1.\n",
    "* Misma arquitectura pero congelando 100 capas de la convnet(y agregando una nueva muestra de pacientes de 3 ) converge alrededor de los 25 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "* Normalizar  el allocation weighitng con sofmax(en la primera iteración asigna todo el peso a la primera posición de memoria)\n",
    "* Usar arquitectura similar a dueling network o inception para tener 2 caminos en las entradas.\n",
    "* Cambiar el modelo original para leer antes que escribir y usar lo leido para sacar una predicción en ese punto en el tiempo(el modelo original lee de la memoria despues de escribir y usa la info leida en el siguiente paso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
